{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohammad-Amin-Jenadele/Autoencoder-Anomaly-Detection-on-Imbalanced-Heart-Disease-Dataset/blob/dev/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nzdqi1bdIPa",
        "outputId": "fb13bd16-1363-4eaf-defa-710bff2e6168"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "liiVkliPJJat"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers , models , optimizers\n",
        "import pandas as pf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /root/.config/kaggle/\n",
        "!cp kaggle.json /root/.config/kaggle/\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "2_Gj8DdXKzIc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the Kaggle API is authenticated\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Define the dataset you want to download\n",
        "dataset_name = 'kamilpytlak/personal-key-indicators-of-heart-disease'\n",
        "\n",
        "# Download the dataset\n",
        "api.dataset_download_files(dataset_name, path='data/', unzip=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k9Bp3SsJZDi",
        "outputId": "45198f0d-b907-4255-b3e5-f55a551842a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "dataset_path = '/content/data/2020/heart_2020_cleaned.csv'\n",
        "dataset = pd.read_csv(dataset_path)"
      ],
      "metadata": {
        "id": "_1U60UdbLaC_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcmagTWzL9I_",
        "outputId": "e3789eaf-25e3-4f6a-9bc8-c4275ea438db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['HeartDisease', 'BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
              "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
              "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
              "       'Asthma', 'KidneyDisease', 'SkinCancer'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "MoBVvzuxLv4o",
        "outputId": "333752fb-408e-43da-f00a-5087734929fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       HeartDisease    BMI Smoking AlcoholDrinking Stroke  PhysicalHealth  \\\n",
              "0                No  16.60     Yes              No     No             3.0   \n",
              "1                No  20.34      No              No    Yes             0.0   \n",
              "2                No  26.58     Yes              No     No            20.0   \n",
              "3                No  24.21      No              No     No             0.0   \n",
              "4                No  23.71      No              No     No            28.0   \n",
              "...             ...    ...     ...             ...    ...             ...   \n",
              "319790          Yes  27.41     Yes              No     No             7.0   \n",
              "319791           No  29.84     Yes              No     No             0.0   \n",
              "319792           No  24.24      No              No     No             0.0   \n",
              "319793           No  32.81      No              No     No             0.0   \n",
              "319794           No  46.56      No              No     No             0.0   \n",
              "\n",
              "        MentalHealth DiffWalking     Sex  AgeCategory      Race Diabetic  \\\n",
              "0               30.0          No  Female        55-59     White      Yes   \n",
              "1                0.0          No  Female  80 or older     White       No   \n",
              "2               30.0          No    Male        65-69     White      Yes   \n",
              "3                0.0          No  Female        75-79     White       No   \n",
              "4                0.0         Yes  Female        40-44     White       No   \n",
              "...              ...         ...     ...          ...       ...      ...   \n",
              "319790           0.0         Yes    Male        60-64  Hispanic      Yes   \n",
              "319791           0.0          No    Male        35-39  Hispanic       No   \n",
              "319792           0.0          No  Female        45-49  Hispanic       No   \n",
              "319793           0.0          No  Female        25-29  Hispanic       No   \n",
              "319794           0.0          No  Female  80 or older  Hispanic       No   \n",
              "\n",
              "       PhysicalActivity  GenHealth  SleepTime Asthma KidneyDisease SkinCancer  \n",
              "0                   Yes  Very good        5.0    Yes            No        Yes  \n",
              "1                   Yes  Very good        7.0     No            No         No  \n",
              "2                   Yes       Fair        8.0    Yes            No         No  \n",
              "3                    No       Good        6.0     No            No        Yes  \n",
              "4                   Yes  Very good        8.0     No            No         No  \n",
              "...                 ...        ...        ...    ...           ...        ...  \n",
              "319790               No       Fair        6.0    Yes            No         No  \n",
              "319791              Yes  Very good        5.0    Yes            No         No  \n",
              "319792              Yes       Good        6.0     No            No         No  \n",
              "319793               No       Good       12.0     No            No         No  \n",
              "319794              Yes       Good        8.0     No            No         No  \n",
              "\n",
              "[319795 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3160889-5be2-4d4d-bc28-10b60a6d039e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>AlcoholDrinking</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>DiffWalking</th>\n",
              "      <th>Sex</th>\n",
              "      <th>AgeCategory</th>\n",
              "      <th>Race</th>\n",
              "      <th>Diabetic</th>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <th>GenHealth</th>\n",
              "      <th>SleepTime</th>\n",
              "      <th>Asthma</th>\n",
              "      <th>KidneyDisease</th>\n",
              "      <th>SkinCancer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No</td>\n",
              "      <td>16.60</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Female</td>\n",
              "      <td>55-59</td>\n",
              "      <td>White</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Very good</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "      <td>20.34</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Female</td>\n",
              "      <td>80 or older</td>\n",
              "      <td>White</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Very good</td>\n",
              "      <td>7.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "      <td>26.58</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Male</td>\n",
              "      <td>65-69</td>\n",
              "      <td>White</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fair</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No</td>\n",
              "      <td>24.21</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Female</td>\n",
              "      <td>75-79</td>\n",
              "      <td>White</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Good</td>\n",
              "      <td>6.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "      <td>23.71</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Female</td>\n",
              "      <td>40-44</td>\n",
              "      <td>White</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Very good</td>\n",
              "      <td>8.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319790</th>\n",
              "      <td>Yes</td>\n",
              "      <td>27.41</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Male</td>\n",
              "      <td>60-64</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fair</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319791</th>\n",
              "      <td>No</td>\n",
              "      <td>29.84</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Male</td>\n",
              "      <td>35-39</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Very good</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319792</th>\n",
              "      <td>No</td>\n",
              "      <td>24.24</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Female</td>\n",
              "      <td>45-49</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good</td>\n",
              "      <td>6.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319793</th>\n",
              "      <td>No</td>\n",
              "      <td>32.81</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Female</td>\n",
              "      <td>25-29</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Good</td>\n",
              "      <td>12.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319794</th>\n",
              "      <td>No</td>\n",
              "      <td>46.56</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Female</td>\n",
              "      <td>80 or older</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Good</td>\n",
              "      <td>8.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319795 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3160889-5be2-4d4d-bc28-10b60a6d039e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3160889-5be2-4d4d-bc28-10b60a6d039e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3160889-5be2-4d4d-bc28-10b60a6d039e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-690ac6cf-8b07-4a39-a5d2-0779acb6ebaa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-690ac6cf-8b07-4a39-a5d2-0779acb6ebaa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-690ac6cf-8b07-4a39-a5d2-0779acb6ebaa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the heart disease distribution\n",
        "counts = dataset['HeartDisease'].value_counts()\n",
        "percentages = counts / counts.sum() * 100\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(\n",
        "    counts,\n",
        "    labels=counts.index,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=140,\n",
        "    colors=['#ff9999','#66b3ff']\n",
        ")\n",
        "plt.title(\"Distribution of Heart Disease\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "07OKGaN6MZGN",
        "outputId": "2e69c2ae-9c83-4c81-853a-1a502b345752"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"Yes\" with 1 and \"No\" with 0 in specific columns\n",
        "dataset['HeartDisease'] = dataset['HeartDisease'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['Smoking'] = dataset['Smoking'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['AlcoholDrinking'] = dataset['AlcoholDrinking'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['Stroke'] = dataset['Stroke'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['DiffWalking'] = dataset['DiffWalking'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['Sex'] = dataset['Sex'].replace({'Male': 1, 'Female': 0})\n",
        "dataset['Diabetic'] = dataset['Diabetic'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['PhysicalActivity'] = dataset['PhysicalActivity'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['Asthma'] = dataset['Asthma'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['KidneyDisease'] = dataset['KidneyDisease'].replace({'Yes': 1, 'No': 0})\n",
        "dataset['SkinCancer'] = dataset['SkinCancer'].replace({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTP_mxExNkau",
        "outputId": "5ab40658-2696-4084-b3eb-fd388267fc93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2323b0f2f828>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['HeartDisease'] = dataset['HeartDisease'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['Smoking'] = dataset['Smoking'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['AlcoholDrinking'] = dataset['AlcoholDrinking'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['Stroke'] = dataset['Stroke'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['DiffWalking'] = dataset['DiffWalking'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['Sex'] = dataset['Sex'].replace({'Male': 1, 'Female': 0})\n",
            "<ipython-input-9-2323b0f2f828>:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['PhysicalActivity'] = dataset['PhysicalActivity'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['Asthma'] = dataset['Asthma'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['KidneyDisease'] = dataset['KidneyDisease'].replace({'Yes': 1, 'No': 0})\n",
            "<ipython-input-9-2323b0f2f828>:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  dataset['SkinCancer'] = dataset['SkinCancer'].replace({'Yes': 1, 'No': 0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "3XYsMANdPU-5",
        "outputId": "ef2b2cc0-4d3a-498c-89f8-1690d81c0879"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        HeartDisease    BMI  Smoking  AlcoholDrinking  Stroke  PhysicalHealth  \\\n",
              "0                  0  16.60        1                0       0             3.0   \n",
              "1                  0  20.34        0                0       1             0.0   \n",
              "2                  0  26.58        1                0       0            20.0   \n",
              "3                  0  24.21        0                0       0             0.0   \n",
              "4                  0  23.71        0                0       0            28.0   \n",
              "...              ...    ...      ...              ...     ...             ...   \n",
              "319790             1  27.41        1                0       0             7.0   \n",
              "319791             0  29.84        1                0       0             0.0   \n",
              "319792             0  24.24        0                0       0             0.0   \n",
              "319793             0  32.81        0                0       0             0.0   \n",
              "319794             0  46.56        0                0       0             0.0   \n",
              "\n",
              "        MentalHealth  DiffWalking  Sex  AgeCategory      Race Diabetic  \\\n",
              "0               30.0            0    0        55-59     White        1   \n",
              "1                0.0            0    0  80 or older     White        0   \n",
              "2               30.0            0    1        65-69     White        1   \n",
              "3                0.0            0    0        75-79     White        0   \n",
              "4                0.0            1    0        40-44     White        0   \n",
              "...              ...          ...  ...          ...       ...      ...   \n",
              "319790           0.0            1    1        60-64  Hispanic        1   \n",
              "319791           0.0            0    1        35-39  Hispanic        0   \n",
              "319792           0.0            0    0        45-49  Hispanic        0   \n",
              "319793           0.0            0    0        25-29  Hispanic        0   \n",
              "319794           0.0            0    0  80 or older  Hispanic        0   \n",
              "\n",
              "        PhysicalActivity  GenHealth  SleepTime  Asthma  KidneyDisease  \\\n",
              "0                      1  Very good        5.0       1              0   \n",
              "1                      1  Very good        7.0       0              0   \n",
              "2                      1       Fair        8.0       1              0   \n",
              "3                      0       Good        6.0       0              0   \n",
              "4                      1  Very good        8.0       0              0   \n",
              "...                  ...        ...        ...     ...            ...   \n",
              "319790                 0       Fair        6.0       1              0   \n",
              "319791                 1  Very good        5.0       1              0   \n",
              "319792                 1       Good        6.0       0              0   \n",
              "319793                 0       Good       12.0       0              0   \n",
              "319794                 1       Good        8.0       0              0   \n",
              "\n",
              "        SkinCancer  \n",
              "0                1  \n",
              "1                0  \n",
              "2                0  \n",
              "3                1  \n",
              "4                0  \n",
              "...            ...  \n",
              "319790           0  \n",
              "319791           0  \n",
              "319792           0  \n",
              "319793           0  \n",
              "319794           0  \n",
              "\n",
              "[319795 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7d7b667-63ad-401e-ac4b-c4372bc5683a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>AlcoholDrinking</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>DiffWalking</th>\n",
              "      <th>Sex</th>\n",
              "      <th>AgeCategory</th>\n",
              "      <th>Race</th>\n",
              "      <th>Diabetic</th>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <th>GenHealth</th>\n",
              "      <th>SleepTime</th>\n",
              "      <th>Asthma</th>\n",
              "      <th>KidneyDisease</th>\n",
              "      <th>SkinCancer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55-59</td>\n",
              "      <td>White</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Very good</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>20.34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80 or older</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Very good</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>26.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>65-69</td>\n",
              "      <td>White</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Fair</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>24.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75-79</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>23.71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>40-44</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Very good</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319790</th>\n",
              "      <td>1</td>\n",
              "      <td>27.41</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60-64</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Fair</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319791</th>\n",
              "      <td>0</td>\n",
              "      <td>29.84</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35-39</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Very good</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319792</th>\n",
              "      <td>0</td>\n",
              "      <td>24.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45-49</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319793</th>\n",
              "      <td>0</td>\n",
              "      <td>32.81</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25-29</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319794</th>\n",
              "      <td>0</td>\n",
              "      <td>46.56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80 or older</td>\n",
              "      <td>Hispanic</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319795 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7d7b667-63ad-401e-ac4b-c4372bc5683a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e7d7b667-63ad-401e-ac4b-c4372bc5683a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e7d7b667-63ad-401e-ac4b-c4372bc5683a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8cc44107-f8f9-47de-b0fc-2019a1f5287f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cc44107-f8f9-47de-b0fc-2019a1f5287f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8cc44107-f8f9-47de-b0fc-2019a1f5287f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['AgeCategory' , 'Race' , 'GenHealth' , 'Diabetic']\n",
        "dataset = pd.get_dummies(dataset, columns=categorical_columns, drop_first=False)\n",
        "boolean_columns = dataset.select_dtypes(include='bool').columns\n",
        "dataset[boolean_columns] = dataset[boolean_columns].astype(int)"
      ],
      "metadata": {
        "id": "04sJ9AdiPksQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "uXNMaYBiQO3B",
        "outputId": "c6487640-fb88-41c8-f6b2-a10b2d1c4175"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        HeartDisease    BMI  Smoking  AlcoholDrinking  Stroke  PhysicalHealth  \\\n",
              "0                  0  16.60        1                0       0             3.0   \n",
              "1                  0  20.34        0                0       1             0.0   \n",
              "2                  0  26.58        1                0       0            20.0   \n",
              "3                  0  24.21        0                0       0             0.0   \n",
              "4                  0  23.71        0                0       0            28.0   \n",
              "...              ...    ...      ...              ...     ...             ...   \n",
              "319790             1  27.41        1                0       0             7.0   \n",
              "319791             0  29.84        1                0       0             0.0   \n",
              "319792             0  24.24        0                0       0             0.0   \n",
              "319793             0  32.81        0                0       0             0.0   \n",
              "319794             0  46.56        0                0       0             0.0   \n",
              "\n",
              "        MentalHealth  DiffWalking  Sex  PhysicalActivity  ...  Race_White  \\\n",
              "0               30.0            0    0                 1  ...           1   \n",
              "1                0.0            0    0                 1  ...           1   \n",
              "2               30.0            0    1                 1  ...           1   \n",
              "3                0.0            0    0                 0  ...           1   \n",
              "4                0.0            1    0                 1  ...           1   \n",
              "...              ...          ...  ...               ...  ...         ...   \n",
              "319790           0.0            1    1                 0  ...           0   \n",
              "319791           0.0            0    1                 1  ...           0   \n",
              "319792           0.0            0    0                 1  ...           0   \n",
              "319793           0.0            0    0                 0  ...           0   \n",
              "319794           0.0            0    0                 1  ...           0   \n",
              "\n",
              "        GenHealth_Excellent  GenHealth_Fair  GenHealth_Good  GenHealth_Poor  \\\n",
              "0                         0               0               0               0   \n",
              "1                         0               0               0               0   \n",
              "2                         0               1               0               0   \n",
              "3                         0               0               1               0   \n",
              "4                         0               0               0               0   \n",
              "...                     ...             ...             ...             ...   \n",
              "319790                    0               1               0               0   \n",
              "319791                    0               0               0               0   \n",
              "319792                    0               0               1               0   \n",
              "319793                    0               0               1               0   \n",
              "319794                    0               0               1               0   \n",
              "\n",
              "        GenHealth_Very good  Diabetic_0  Diabetic_1  \\\n",
              "0                         1           0           1   \n",
              "1                         1           1           0   \n",
              "2                         0           0           1   \n",
              "3                         0           1           0   \n",
              "4                         1           1           0   \n",
              "...                     ...         ...         ...   \n",
              "319790                    0           0           1   \n",
              "319791                    1           1           0   \n",
              "319792                    0           1           0   \n",
              "319793                    0           1           0   \n",
              "319794                    0           1           0   \n",
              "\n",
              "        Diabetic_No, borderline diabetes  Diabetic_Yes (during pregnancy)  \n",
              "0                                      0                                0  \n",
              "1                                      0                                0  \n",
              "2                                      0                                0  \n",
              "3                                      0                                0  \n",
              "4                                      0                                0  \n",
              "...                                  ...                              ...  \n",
              "319790                                 0                                0  \n",
              "319791                                 0                                0  \n",
              "319792                                 0                                0  \n",
              "319793                                 0                                0  \n",
              "319794                                 0                                0  \n",
              "\n",
              "[319795 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1590348-9bf4-421f-80ec-a12f2572ed1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>AlcoholDrinking</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>DiffWalking</th>\n",
              "      <th>Sex</th>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <th>...</th>\n",
              "      <th>Race_White</th>\n",
              "      <th>GenHealth_Excellent</th>\n",
              "      <th>GenHealth_Fair</th>\n",
              "      <th>GenHealth_Good</th>\n",
              "      <th>GenHealth_Poor</th>\n",
              "      <th>GenHealth_Very good</th>\n",
              "      <th>Diabetic_0</th>\n",
              "      <th>Diabetic_1</th>\n",
              "      <th>Diabetic_No, borderline diabetes</th>\n",
              "      <th>Diabetic_Yes (during pregnancy)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>20.34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>26.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>24.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>23.71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319790</th>\n",
              "      <td>1</td>\n",
              "      <td>27.41</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319791</th>\n",
              "      <td>0</td>\n",
              "      <td>29.84</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319792</th>\n",
              "      <td>0</td>\n",
              "      <td>24.24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319793</th>\n",
              "      <td>0</td>\n",
              "      <td>32.81</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319794</th>\n",
              "      <td>0</td>\n",
              "      <td>46.56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319795 rows × 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1590348-9bf4-421f-80ec-a12f2572ed1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1590348-9bf4-421f-80ec-a12f2572ed1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1590348-9bf4-421f-80ec-a12f2572ed1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b1ffc6a-fae9-43e1-ac5f-357b23c1c8e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b1ffc6a-fae9-43e1-ac5f-357b23c1c8e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b1ffc6a-fae9-43e1-ac5f-357b23c1c8e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9PpsUBDRGdt",
        "outputId": "929aaad8-26af-4201-9974-9251febbf03d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['HeartDisease', 'BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
              "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex',\n",
              "       'PhysicalActivity', 'SleepTime', 'Asthma', 'KidneyDisease',\n",
              "       'SkinCancer', 'AgeCategory_18-24', 'AgeCategory_25-29',\n",
              "       'AgeCategory_30-34', 'AgeCategory_35-39', 'AgeCategory_40-44',\n",
              "       'AgeCategory_45-49', 'AgeCategory_50-54', 'AgeCategory_55-59',\n",
              "       'AgeCategory_60-64', 'AgeCategory_65-69', 'AgeCategory_70-74',\n",
              "       'AgeCategory_75-79', 'AgeCategory_80 or older',\n",
              "       'Race_American Indian/Alaskan Native', 'Race_Asian', 'Race_Black',\n",
              "       'Race_Hispanic', 'Race_Other', 'Race_White', 'GenHealth_Excellent',\n",
              "       'GenHealth_Fair', 'GenHealth_Good', 'GenHealth_Poor',\n",
              "       'GenHealth_Very good', 'Diabetic_0', 'Diabetic_1',\n",
              "       'Diabetic_No, borderline diabetes', 'Diabetic_Yes (during pregnancy)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "AOimYQJxM9nB",
        "outputId": "79401335-d636-4805-fb32-0546a30eb7d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        HeartDisease       BMI  Smoking  AlcoholDrinking  Stroke  \\\n",
              "0                0.0  0.055294      1.0              0.0     0.0   \n",
              "1                0.0  0.100447      0.0              0.0     1.0   \n",
              "2                0.0  0.175782      1.0              0.0     0.0   \n",
              "3                0.0  0.147169      0.0              0.0     0.0   \n",
              "4                0.0  0.141132      0.0              0.0     0.0   \n",
              "...              ...       ...      ...              ...     ...   \n",
              "319790           1.0  0.185802      1.0              0.0     0.0   \n",
              "319791           0.0  0.215139      1.0              0.0     0.0   \n",
              "319792           0.0  0.147531      0.0              0.0     0.0   \n",
              "319793           0.0  0.250996      0.0              0.0     0.0   \n",
              "319794           0.0  0.416999      0.0              0.0     0.0   \n",
              "\n",
              "        PhysicalHealth  MentalHealth  DiffWalking  Sex  PhysicalActivity  ...  \\\n",
              "0             0.100000           1.0          0.0  0.0               1.0  ...   \n",
              "1             0.000000           0.0          0.0  0.0               1.0  ...   \n",
              "2             0.666667           1.0          0.0  1.0               1.0  ...   \n",
              "3             0.000000           0.0          0.0  0.0               0.0  ...   \n",
              "4             0.933333           0.0          1.0  0.0               1.0  ...   \n",
              "...                ...           ...          ...  ...               ...  ...   \n",
              "319790        0.233333           0.0          1.0  1.0               0.0  ...   \n",
              "319791        0.000000           0.0          0.0  1.0               1.0  ...   \n",
              "319792        0.000000           0.0          0.0  0.0               1.0  ...   \n",
              "319793        0.000000           0.0          0.0  0.0               0.0  ...   \n",
              "319794        0.000000           0.0          0.0  0.0               1.0  ...   \n",
              "\n",
              "        Race_White  GenHealth_Excellent  GenHealth_Fair  GenHealth_Good  \\\n",
              "0              1.0                  0.0             0.0             0.0   \n",
              "1              1.0                  0.0             0.0             0.0   \n",
              "2              1.0                  0.0             1.0             0.0   \n",
              "3              1.0                  0.0             0.0             1.0   \n",
              "4              1.0                  0.0             0.0             0.0   \n",
              "...            ...                  ...             ...             ...   \n",
              "319790         0.0                  0.0             1.0             0.0   \n",
              "319791         0.0                  0.0             0.0             0.0   \n",
              "319792         0.0                  0.0             0.0             1.0   \n",
              "319793         0.0                  0.0             0.0             1.0   \n",
              "319794         0.0                  0.0             0.0             1.0   \n",
              "\n",
              "        GenHealth_Poor  GenHealth_Very good  Diabetic_0  Diabetic_1  \\\n",
              "0                  0.0                  1.0         0.0         1.0   \n",
              "1                  0.0                  1.0         1.0         0.0   \n",
              "2                  0.0                  0.0         0.0         1.0   \n",
              "3                  0.0                  0.0         1.0         0.0   \n",
              "4                  0.0                  1.0         1.0         0.0   \n",
              "...                ...                  ...         ...         ...   \n",
              "319790             0.0                  0.0         0.0         1.0   \n",
              "319791             0.0                  1.0         1.0         0.0   \n",
              "319792             0.0                  0.0         1.0         0.0   \n",
              "319793             0.0                  0.0         1.0         0.0   \n",
              "319794             0.0                  0.0         1.0         0.0   \n",
              "\n",
              "        Diabetic_No, borderline diabetes  Diabetic_Yes (during pregnancy)  \n",
              "0                                    0.0                              0.0  \n",
              "1                                    0.0                              0.0  \n",
              "2                                    0.0                              0.0  \n",
              "3                                    0.0                              0.0  \n",
              "4                                    0.0                              0.0  \n",
              "...                                  ...                              ...  \n",
              "319790                               0.0                              0.0  \n",
              "319791                               0.0                              0.0  \n",
              "319792                               0.0                              0.0  \n",
              "319793                               0.0                              0.0  \n",
              "319794                               0.0                              0.0  \n",
              "\n",
              "[319795 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0384d9f-8b01-4577-93f3-1f8cc79a484f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Smoking</th>\n",
              "      <th>AlcoholDrinking</th>\n",
              "      <th>Stroke</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>DiffWalking</th>\n",
              "      <th>Sex</th>\n",
              "      <th>PhysicalActivity</th>\n",
              "      <th>...</th>\n",
              "      <th>Race_White</th>\n",
              "      <th>GenHealth_Excellent</th>\n",
              "      <th>GenHealth_Fair</th>\n",
              "      <th>GenHealth_Good</th>\n",
              "      <th>GenHealth_Poor</th>\n",
              "      <th>GenHealth_Very good</th>\n",
              "      <th>Diabetic_0</th>\n",
              "      <th>Diabetic_1</th>\n",
              "      <th>Diabetic_No, borderline diabetes</th>\n",
              "      <th>Diabetic_Yes (during pregnancy)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055294</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.175782</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147169</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.141132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319790</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.185802</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319791</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.215139</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319792</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319793</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319794</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.416999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319795 rows × 42 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0384d9f-8b01-4577-93f3-1f8cc79a484f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0384d9f-8b01-4577-93f3-1f8cc79a484f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0384d9f-8b01-4577-93f3-1f8cc79a484f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0c170c9-a2d6-45ca-be26-4421659c67b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0c170c9-a2d6-45ca-be26-4421659c67b3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0c170c9-a2d6-45ca-be26-4421659c67b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset split : For no disease 80% train , 10% validataion and 10% test\n",
        "# x_anomaly = concat(has_disease , x_valid , x_test)\n",
        "no_disease = dataset[dataset['HeartDisease'] == 0]\n",
        "has_disease = dataset[dataset['HeartDisease'] == 1]\n",
        "x_train, x_temp = train_test_split(no_disease, test_size=0.20)\n",
        "x_valid, x_test = train_test_split(x_temp, test_size=0.50)\n",
        "x_contains_anomaly = pd.concat([x_test, has_disease], ignore_index=True)\n",
        "x_train = x_train.drop(columns=['HeartDisease'])\n",
        "x_valid = x_valid.drop(columns=['HeartDisease'])\n",
        "x_test = x_test.drop(columns=['HeartDisease'])\n",
        "print(f\"x_train size: {x_train.shape}\")\n",
        "print(f\"x_valid size: {x_valid.shape}\")\n",
        "print(f\"x_test size: {x_test.shape}\")\n",
        "print(f\"x_contains_anomaly size: {x_contains_anomaly.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u5IT-p0TQot",
        "outputId": "4ac921da-0265-44eb-8c80-649db21f7ea1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train size: (233937, 41)\n",
            "x_valid size: (29242, 41)\n",
            "x_test size: (29243, 41)\n",
            "x_contains_anomaly size: (56616, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = models.Sequential([\n",
        "    # Encoder\n",
        "    layers.Input(shape=(x_train.shape[1],)),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Decoder\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Output layer: reconstructing the original input\n",
        "    layers.Dense(x_train.shape[1], activation=\"linear\")\n",
        "])\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3o0Rjm9iYQOz",
        "outputId": "2e07d30b-f903-4a7f-e3aa-0f9c53243e46"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m5,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)                  │           \u001b[38;5;34m5,289\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,289</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,361\u001b[0m (134.22 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,361</span> (134.22 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,433\u001b[0m (130.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,433</span> (130.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m928\u001b[0m (3.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">928</span> (3.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=3e-4),  # You can adjust the learning rate if needed\n",
        "    loss=keras.losses.MeanSquaredError()  # Use Mean Squared Error for reconstruction loss\n",
        ")"
      ],
      "metadata": {
        "id": "WghggWXncHpN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Metric to monitor\n",
        "    patience=100,          # Number of epochs to wait for improvement before stopping\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric\n",
        ")"
      ],
      "metadata": {
        "id": "eK4_DQ7qdZTT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(\n",
        "    x_train,\n",
        "    x_train,\n",
        "    epochs=1000,\n",
        "    batch_size=1024,\n",
        "    validation_data=(x_valid, x_valid),\n",
        "    shuffle=True ,\n",
        "   callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYJaEdD_cia_",
        "outputId": "2d2babb5-44ab-4d52-a5f8-07754a095302"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 39ms/step - loss: 1.1976 - val_loss: 0.1121\n",
            "Epoch 2/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3525 - val_loss: 0.0835\n",
            "Epoch 3/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2131 - val_loss: 0.0747\n",
            "Epoch 4/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1550 - val_loss: 0.0706\n",
            "Epoch 5/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1216 - val_loss: 0.0672\n",
            "Epoch 6/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1003 - val_loss: 0.0641\n",
            "Epoch 7/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0613\n",
            "Epoch 8/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0775 - val_loss: 0.0595\n",
            "Epoch 9/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0718 - val_loss: 0.0583\n",
            "Epoch 10/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0684 - val_loss: 0.0572\n",
            "Epoch 11/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0662 - val_loss: 0.0564\n",
            "Epoch 12/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0646 - val_loss: 0.0556\n",
            "Epoch 13/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0635 - val_loss: 0.0550\n",
            "Epoch 14/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0626 - val_loss: 0.0542\n",
            "Epoch 15/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0618 - val_loss: 0.0532\n",
            "Epoch 16/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0610 - val_loss: 0.0521\n",
            "Epoch 17/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0510\n",
            "Epoch 18/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0504\n",
            "Epoch 19/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0584 - val_loss: 0.0494\n",
            "Epoch 20/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0576 - val_loss: 0.0486\n",
            "Epoch 21/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0569 - val_loss: 0.0477\n",
            "Epoch 22/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0561 - val_loss: 0.0468\n",
            "Epoch 23/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0554 - val_loss: 0.0457\n",
            "Epoch 24/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0544 - val_loss: 0.0445\n",
            "Epoch 25/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0537 - val_loss: 0.0437\n",
            "Epoch 26/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0527 - val_loss: 0.0432\n",
            "Epoch 27/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0520 - val_loss: 0.0428\n",
            "Epoch 28/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0514 - val_loss: 0.0425\n",
            "Epoch 29/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0509 - val_loss: 0.0422\n",
            "Epoch 30/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0503 - val_loss: 0.0419\n",
            "Epoch 31/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0498 - val_loss: 0.0416\n",
            "Epoch 32/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0492 - val_loss: 0.0411\n",
            "Epoch 33/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0487 - val_loss: 0.0406\n",
            "Epoch 34/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0480 - val_loss: 0.0402\n",
            "Epoch 35/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0473 - val_loss: 0.0397\n",
            "Epoch 36/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0469 - val_loss: 0.0394\n",
            "Epoch 37/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0462 - val_loss: 0.0389\n",
            "Epoch 38/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0458 - val_loss: 0.0385\n",
            "Epoch 39/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.0382\n",
            "Epoch 40/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0449 - val_loss: 0.0379\n",
            "Epoch 41/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0444 - val_loss: 0.0377\n",
            "Epoch 42/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0441 - val_loss: 0.0376\n",
            "Epoch 43/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0438 - val_loss: 0.0375\n",
            "Epoch 44/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0435 - val_loss: 0.0373\n",
            "Epoch 45/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0432 - val_loss: 0.0372\n",
            "Epoch 46/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0430 - val_loss: 0.0371\n",
            "Epoch 47/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.0369\n",
            "Epoch 48/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0424 - val_loss: 0.0368\n",
            "Epoch 49/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0423 - val_loss: 0.0365\n",
            "Epoch 50/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - val_loss: 0.0359\n",
            "Epoch 51/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.0354\n",
            "Epoch 52/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0415 - val_loss: 0.0350\n",
            "Epoch 53/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0412 - val_loss: 0.0346\n",
            "Epoch 54/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0410 - val_loss: 0.0342\n",
            "Epoch 55/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0406 - val_loss: 0.0339\n",
            "Epoch 56/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0404 - val_loss: 0.0336\n",
            "Epoch 57/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0334\n",
            "Epoch 58/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - val_loss: 0.0332\n",
            "Epoch 59/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0330\n",
            "Epoch 60/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0329\n",
            "Epoch 61/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0394 - val_loss: 0.0325\n",
            "Epoch 62/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0392 - val_loss: 0.0321\n",
            "Epoch 63/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - val_loss: 0.0319\n",
            "Epoch 64/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0317\n",
            "Epoch 65/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0316\n",
            "Epoch 66/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0314\n",
            "Epoch 67/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0382 - val_loss: 0.0313\n",
            "Epoch 68/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0313\n",
            "Epoch 69/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - val_loss: 0.0312\n",
            "Epoch 70/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0311\n",
            "Epoch 71/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.0311\n",
            "Epoch 72/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0310\n",
            "Epoch 73/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.0309\n",
            "Epoch 74/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0307\n",
            "Epoch 75/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0304\n",
            "Epoch 76/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - val_loss: 0.0302\n",
            "Epoch 77/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0300\n",
            "Epoch 78/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0298\n",
            "Epoch 79/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0297\n",
            "Epoch 80/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0292\n",
            "Epoch 81/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0290\n",
            "Epoch 82/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.0287\n",
            "Epoch 83/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0286\n",
            "Epoch 84/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - val_loss: 0.0286\n",
            "Epoch 85/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0281\n",
            "Epoch 86/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0281\n",
            "Epoch 87/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0276\n",
            "Epoch 88/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0276\n",
            "Epoch 89/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0275\n",
            "Epoch 90/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - val_loss: 0.0271\n",
            "Epoch 91/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - val_loss: 0.0264\n",
            "Epoch 92/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0262\n",
            "Epoch 93/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0342 - val_loss: 0.0253\n",
            "Epoch 94/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0339 - val_loss: 0.0248\n",
            "Epoch 95/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0335 - val_loss: 0.0245\n",
            "Epoch 96/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0244\n",
            "Epoch 97/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0242\n",
            "Epoch 98/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.0240\n",
            "Epoch 99/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0238\n",
            "Epoch 100/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.0237\n",
            "Epoch 101/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0235\n",
            "Epoch 102/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.0235\n",
            "Epoch 103/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0233\n",
            "Epoch 104/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.0231\n",
            "Epoch 105/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.0231\n",
            "Epoch 106/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0231\n",
            "Epoch 107/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0230\n",
            "Epoch 108/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0229\n",
            "Epoch 109/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0229\n",
            "Epoch 110/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0227\n",
            "Epoch 111/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.0228\n",
            "Epoch 112/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0227\n",
            "Epoch 113/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0226\n",
            "Epoch 114/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.0225\n",
            "Epoch 115/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.0225\n",
            "Epoch 116/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.0226\n",
            "Epoch 117/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0227\n",
            "Epoch 118/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0311 - val_loss: 0.0225\n",
            "Epoch 119/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0226\n",
            "Epoch 120/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0224\n",
            "Epoch 121/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0223\n",
            "Epoch 122/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0225\n",
            "Epoch 123/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0222\n",
            "Epoch 124/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0223\n",
            "Epoch 125/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0223\n",
            "Epoch 126/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0223\n",
            "Epoch 127/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0222\n",
            "Epoch 128/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.0221\n",
            "Epoch 129/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0221\n",
            "Epoch 130/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0222\n",
            "Epoch 131/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0222\n",
            "Epoch 132/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0221\n",
            "Epoch 133/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.0219\n",
            "Epoch 134/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.0219\n",
            "Epoch 135/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0218\n",
            "Epoch 136/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.0218\n",
            "Epoch 137/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0219\n",
            "Epoch 138/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0216\n",
            "Epoch 139/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0301 - val_loss: 0.0217\n",
            "Epoch 140/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0300 - val_loss: 0.0216\n",
            "Epoch 141/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0215\n",
            "Epoch 142/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0213\n",
            "Epoch 143/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0216\n",
            "Epoch 144/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0214\n",
            "Epoch 145/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.0214\n",
            "Epoch 146/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0213\n",
            "Epoch 147/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.0213\n",
            "Epoch 148/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0211\n",
            "Epoch 149/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0211\n",
            "Epoch 150/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0296 - val_loss: 0.0209\n",
            "Epoch 151/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0208\n",
            "Epoch 152/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0207\n",
            "Epoch 153/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0205\n",
            "Epoch 154/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0294 - val_loss: 0.0205\n",
            "Epoch 155/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.0206\n",
            "Epoch 156/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0203\n",
            "Epoch 157/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0202\n",
            "Epoch 158/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0204\n",
            "Epoch 159/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0203\n",
            "Epoch 160/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0291 - val_loss: 0.0203\n",
            "Epoch 161/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0291 - val_loss: 0.0202\n",
            "Epoch 162/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0291 - val_loss: 0.0201\n",
            "Epoch 163/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0291 - val_loss: 0.0200\n",
            "Epoch 164/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.0200\n",
            "Epoch 165/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0203\n",
            "Epoch 166/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.0200\n",
            "Epoch 167/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0200\n",
            "Epoch 168/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.0199\n",
            "Epoch 169/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0198\n",
            "Epoch 170/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0199\n",
            "Epoch 171/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0198\n",
            "Epoch 172/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0287 - val_loss: 0.0197\n",
            "Epoch 173/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0198\n",
            "Epoch 174/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - val_loss: 0.0196\n",
            "Epoch 175/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0287 - val_loss: 0.0197\n",
            "Epoch 176/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0197\n",
            "Epoch 177/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0196\n",
            "Epoch 178/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0198\n",
            "Epoch 179/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0195\n",
            "Epoch 180/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.0193\n",
            "Epoch 181/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0194\n",
            "Epoch 182/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.0193\n",
            "Epoch 183/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0194\n",
            "Epoch 184/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0194\n",
            "Epoch 185/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0193\n",
            "Epoch 186/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0193\n",
            "Epoch 187/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0193\n",
            "Epoch 188/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.0193\n",
            "Epoch 189/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0193\n",
            "Epoch 190/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.0192\n",
            "Epoch 191/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0192\n",
            "Epoch 192/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0190\n",
            "Epoch 193/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.0188\n",
            "Epoch 194/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0186\n",
            "Epoch 195/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0185\n",
            "Epoch 196/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0181\n",
            "Epoch 197/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0177\n",
            "Epoch 198/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0176\n",
            "Epoch 199/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0174\n",
            "Epoch 200/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0175\n",
            "Epoch 201/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0175\n",
            "Epoch 202/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0274 - val_loss: 0.0173\n",
            "Epoch 203/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0274 - val_loss: 0.0174\n",
            "Epoch 204/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0173\n",
            "Epoch 205/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0173\n",
            "Epoch 206/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0174\n",
            "Epoch 207/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0272 - val_loss: 0.0171\n",
            "Epoch 208/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0270 - val_loss: 0.0173\n",
            "Epoch 209/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0169\n",
            "Epoch 210/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0171\n",
            "Epoch 211/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0169\n",
            "Epoch 212/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0168\n",
            "Epoch 213/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0169\n",
            "Epoch 214/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0168\n",
            "Epoch 215/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0168\n",
            "Epoch 216/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0168\n",
            "Epoch 217/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0166\n",
            "Epoch 218/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0167\n",
            "Epoch 219/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0167\n",
            "Epoch 220/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0164\n",
            "Epoch 221/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0165\n",
            "Epoch 222/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0163\n",
            "Epoch 223/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0166\n",
            "Epoch 224/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0160\n",
            "Epoch 225/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0160\n",
            "Epoch 226/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0159\n",
            "Epoch 227/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0160\n",
            "Epoch 228/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0162\n",
            "Epoch 229/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0161\n",
            "Epoch 230/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0159\n",
            "Epoch 231/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0157\n",
            "Epoch 232/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0159\n",
            "Epoch 233/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0156\n",
            "Epoch 234/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0158\n",
            "Epoch 235/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0157\n",
            "Epoch 236/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0157\n",
            "Epoch 237/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0156\n",
            "Epoch 238/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0154\n",
            "Epoch 239/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0157\n",
            "Epoch 240/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0157\n",
            "Epoch 241/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0156\n",
            "Epoch 242/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0157\n",
            "Epoch 243/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0155\n",
            "Epoch 244/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0156\n",
            "Epoch 245/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0155\n",
            "Epoch 246/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0155\n",
            "Epoch 247/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0156\n",
            "Epoch 248/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0156\n",
            "Epoch 249/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0157\n",
            "Epoch 250/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0155\n",
            "Epoch 251/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0158\n",
            "Epoch 252/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0156\n",
            "Epoch 253/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0153\n",
            "Epoch 254/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0155\n",
            "Epoch 255/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0154\n",
            "Epoch 256/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0155\n",
            "Epoch 257/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0155\n",
            "Epoch 258/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0156\n",
            "Epoch 259/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0154\n",
            "Epoch 260/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0153\n",
            "Epoch 261/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0155\n",
            "Epoch 262/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0153\n",
            "Epoch 263/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0155\n",
            "Epoch 264/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0154\n",
            "Epoch 265/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0156\n",
            "Epoch 266/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0156\n",
            "Epoch 267/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0153\n",
            "Epoch 268/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0153\n",
            "Epoch 269/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0153\n",
            "Epoch 270/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0156\n",
            "Epoch 271/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0154\n",
            "Epoch 272/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0153\n",
            "Epoch 273/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0153\n",
            "Epoch 274/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0153\n",
            "Epoch 275/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0154\n",
            "Epoch 276/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0151\n",
            "Epoch 277/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0154\n",
            "Epoch 278/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0156\n",
            "Epoch 279/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0151\n",
            "Epoch 280/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0153\n",
            "Epoch 281/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "Epoch 282/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0152\n",
            "Epoch 283/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0152\n",
            "Epoch 284/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0151\n",
            "Epoch 285/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0153\n",
            "Epoch 286/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0152\n",
            "Epoch 287/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0152\n",
            "Epoch 288/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0153\n",
            "Epoch 289/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0152\n",
            "Epoch 290/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0153\n",
            "Epoch 291/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0152\n",
            "Epoch 292/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "Epoch 293/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "Epoch 294/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0153\n",
            "Epoch 295/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0151\n",
            "Epoch 296/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0152\n",
            "Epoch 297/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0150\n",
            "Epoch 298/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0152\n",
            "Epoch 299/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0151\n",
            "Epoch 300/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0150\n",
            "Epoch 301/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0152\n",
            "Epoch 302/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0150\n",
            "Epoch 303/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0150\n",
            "Epoch 304/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0151\n",
            "Epoch 305/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "Epoch 306/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0150\n",
            "Epoch 307/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0154\n",
            "Epoch 308/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0150\n",
            "Epoch 309/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0152\n",
            "Epoch 310/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "Epoch 311/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0151\n",
            "Epoch 312/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0150\n",
            "Epoch 313/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0151\n",
            "Epoch 314/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0150\n",
            "Epoch 315/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0150\n",
            "Epoch 316/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0149\n",
            "Epoch 317/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0152\n",
            "Epoch 318/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0150\n",
            "Epoch 319/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0151\n",
            "Epoch 320/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0149\n",
            "Epoch 321/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0149\n",
            "Epoch 322/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0151\n",
            "Epoch 323/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 324/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0150\n",
            "Epoch 325/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0153\n",
            "Epoch 326/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0149\n",
            "Epoch 327/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 328/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 329/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0151\n",
            "Epoch 330/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0150\n",
            "Epoch 331/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0149\n",
            "Epoch 332/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0149\n",
            "Epoch 333/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0148\n",
            "Epoch 334/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0149\n",
            "Epoch 335/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0150\n",
            "Epoch 336/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0150\n",
            "Epoch 337/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0150\n",
            "Epoch 338/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0151\n",
            "Epoch 339/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0151\n",
            "Epoch 340/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 341/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 342/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 343/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 344/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0151\n",
            "Epoch 345/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0148\n",
            "Epoch 346/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 347/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 348/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0148\n",
            "Epoch 349/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 350/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0150\n",
            "Epoch 351/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0149\n",
            "Epoch 352/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0151\n",
            "Epoch 353/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0148\n",
            "Epoch 354/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0148\n",
            "Epoch 355/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0148\n",
            "Epoch 356/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 357/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 358/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 359/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 360/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 361/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0148\n",
            "Epoch 362/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0250 - val_loss: 0.0150\n",
            "Epoch 363/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 364/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0151\n",
            "Epoch 365/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 366/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0151\n",
            "Epoch 367/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0149\n",
            "Epoch 368/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0146\n",
            "Epoch 369/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0152\n",
            "Epoch 370/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 371/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 372/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 373/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 374/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0151\n",
            "Epoch 375/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 376/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 377/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 378/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0151\n",
            "Epoch 379/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 380/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 381/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0150\n",
            "Epoch 382/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 383/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 384/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 385/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 386/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 387/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 388/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0150\n",
            "Epoch 389/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 390/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 391/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0150\n",
            "Epoch 392/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 393/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0150\n",
            "Epoch 394/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0146\n",
            "Epoch 395/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 396/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 397/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 398/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 399/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0150\n",
            "Epoch 400/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 401/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0147\n",
            "Epoch 402/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 403/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 404/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0147\n",
            "Epoch 405/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0150\n",
            "Epoch 406/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 407/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0150\n",
            "Epoch 408/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0148\n",
            "Epoch 409/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 410/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 411/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 412/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0149\n",
            "Epoch 413/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0151\n",
            "Epoch 414/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 415/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 416/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 417/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 418/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 419/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0151\n",
            "Epoch 420/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 421/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 422/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 423/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 424/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 425/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 426/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0150\n",
            "Epoch 427/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0149\n",
            "Epoch 428/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 429/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 430/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0146\n",
            "Epoch 431/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 432/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0150\n",
            "Epoch 433/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 434/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0146\n",
            "Epoch 435/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0150\n",
            "Epoch 436/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 437/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 438/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0146\n",
            "Epoch 439/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 440/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0147\n",
            "Epoch 441/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 442/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 443/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0150\n",
            "Epoch 444/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 445/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0149\n",
            "Epoch 446/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 447/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 448/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 449/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 450/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 451/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 452/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 453/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 454/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 455/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 456/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 457/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 458/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 459/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 460/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 461/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0150\n",
            "Epoch 462/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 463/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 464/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 465/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 466/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0150\n",
            "Epoch 467/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0149\n",
            "Epoch 468/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 469/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 470/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 471/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 472/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 473/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 474/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 475/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 476/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0151\n",
            "Epoch 477/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0146\n",
            "Epoch 478/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 479/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 480/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 481/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 482/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0149\n",
            "Epoch 483/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 484/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 485/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0146\n",
            "Epoch 486/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 487/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 488/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 489/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 490/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 491/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 492/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 493/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 494/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0148\n",
            "Epoch 495/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 496/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 497/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 498/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0145\n",
            "Epoch 499/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 500/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 501/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 502/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 503/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 504/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 505/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 506/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 507/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 508/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 509/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 510/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 511/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 512/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 513/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 514/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 515/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0247 - val_loss: 0.0145\n",
            "Epoch 516/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 517/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 518/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 519/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 520/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 521/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 522/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 523/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0148\n",
            "Epoch 524/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 525/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 526/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0145\n",
            "Epoch 527/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 528/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 529/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 530/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 531/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 532/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 533/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 534/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 535/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 536/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 537/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 538/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 539/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 540/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 541/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 542/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0149\n",
            "Epoch 543/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 544/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0146\n",
            "Epoch 545/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 546/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0145\n",
            "Epoch 547/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 548/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 549/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 550/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 551/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 552/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 553/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0145\n",
            "Epoch 554/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0147\n",
            "Epoch 555/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 556/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 557/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 558/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 559/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 560/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0149\n",
            "Epoch 561/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 562/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 563/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 564/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 565/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 566/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0149\n",
            "Epoch 567/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 568/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 569/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 570/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 571/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 572/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 573/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 574/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 575/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 576/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0145\n",
            "Epoch 577/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 578/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 579/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 580/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 581/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 582/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 583/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 584/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 585/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 586/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 587/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 588/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 589/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 590/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0145\n",
            "Epoch 591/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 592/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 593/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 594/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 595/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0143\n",
            "Epoch 596/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 597/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 598/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 599/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 600/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 601/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 602/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 603/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 604/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 605/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 606/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 607/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0148\n",
            "Epoch 608/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0148\n",
            "Epoch 609/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 610/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 611/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 612/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 613/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0147\n",
            "Epoch 614/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 615/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 616/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 617/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 618/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0150\n",
            "Epoch 619/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 620/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 621/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0146\n",
            "Epoch 622/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 623/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 624/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 625/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 626/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 627/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 628/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0144\n",
            "Epoch 629/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0144\n",
            "Epoch 630/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 631/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 632/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 633/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0244 - val_loss: 0.0146\n",
            "Epoch 634/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 635/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0145\n",
            "Epoch 636/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 637/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 638/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 639/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 640/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0146\n",
            "Epoch 641/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 642/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 643/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 644/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 645/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 646/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 647/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0147\n",
            "Epoch 648/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 649/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 650/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 651/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 652/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 653/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 654/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 655/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 656/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 657/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 658/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 659/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 660/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 661/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 662/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0146\n",
            "Epoch 663/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 664/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 665/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0147\n",
            "Epoch 666/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 667/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 668/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0144\n",
            "Epoch 669/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 670/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0145\n",
            "Epoch 671/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 672/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 673/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 674/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0144\n",
            "Epoch 675/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0144\n",
            "Epoch 676/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0147\n",
            "Epoch 677/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 678/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0144\n",
            "Epoch 679/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 680/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 681/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0148\n",
            "Epoch 682/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 683/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 684/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 685/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0146\n",
            "Epoch 686/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0146\n",
            "Epoch 687/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0147\n",
            "Epoch 688/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0145\n",
            "Epoch 689/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0144\n",
            "Epoch 690/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0145\n",
            "Epoch 691/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0146\n",
            "Epoch 692/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0144\n",
            "Epoch 693/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0147\n",
            "Epoch 694/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0146\n",
            "Epoch 695/1000\n",
            "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "qUoewmt7cxds",
        "outputId": "967e08f6-eabe-4d16-db45-3ec3b22bbbeb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf8klEQVR4nO3deVwV5eIG8GfOOZwDh11ZVRT3XTFQLppLSeFyuWmbmTeRUm+mZpn3lplrJS3m5aZebVPbTK/91Ly5hVxtMQpz33IpBVMBUdllO+f9/TGcgSOIgAOD8Hw/zedw3nln5p3hJM95550ZSQghQERERNRA6LRuABEREZGaGG6IiIioQWG4ISIiogaF4YaIiIgaFIYbIiIialAYboiIiKhBYbghIiKiBoXhhoiIiBoUhhsiIiJqUBhuiOrQuHHjEBgYWKNl582bB0mS1G1QPXPu3DlIkoTVq1fX+bYlScK8efOU96tXr4YkSTh37twtlw0MDMS4ceNUbc/tfFaIGjuGGyLIf9iqMu3evVvrpjZ6zz77LCRJwpkzZ25aZ9asWZAkCYcPH67DllXfxYsXMW/ePBw8eFDrpihsAXPRokVaN4WoxgxaN4CoPvj000/t3n/yySeIi4srV965c+fb2s4HH3wAq9Vao2VfeeUVvPTSS7e1/YZgzJgxWLJkCdasWYM5c+ZUWOeLL75A9+7d0aNHjxpv54knnsBjjz0Gk8lU43XcysWLFzF//nwEBgYiKCjIbt7tfFaIGjuGGyIAf/3rX+3e//TTT4iLiytXfqO8vDyYzeYqb8fBwaFG7QMAg8EAg4H/y4aGhqJdu3b44osvKgw3CQkJOHv2LN54443b2o5er4der7+tddyO2/msEDV2PC1FVEWDBg1Ct27dsG/fPgwYMABmsxkvv/wyAOCrr77C8OHD0axZM5hMJrRt2xavvvoqLBaL3TpuHEdR9hTA+++/j7Zt28JkMqF3797Yu3ev3bIVjbmRJAlTpkzBpk2b0K1bN5hMJnTt2hXbt28v1/7du3cjJCQEjo6OaNu2Ld57770qj+P5/vvv8cgjj6Bly5YwmUwICAjA888/j+vXr5fbPxcXF1y4cAEjRoyAi4sLvL29MWPGjHLHIiMjA+PGjYO7uzs8PDwQFRWFjIyMW7YFkHtvfv31V+zfv7/cvDVr1kCSJIwePRqFhYWYM2cOgoOD4e7uDmdnZ/Tv3x+7du265TYqGnMjhMBrr72GFi1awGw245577sGxY8fKLXv16lXMmDED3bt3h4uLC9zc3DB06FAcOnRIqbN792707t0bABAdHa2c+rSNN6pozE1ubi5eeOEFBAQEwGQyoWPHjli0aBGEEHb1qvO5qKm0tDQ89dRT8PX1haOjI3r27ImPP/64XL21a9ciODgYrq6ucHNzQ/fu3fGvf/1LmV9UVIT58+ejffv2cHR0RNOmTXH33XcjLi5OtbZS48OvgUTVcOXKFQwdOhSPPfYY/vrXv8LX1xeA/IfQxcUF06dPh4uLC/73v/9hzpw5yMrKwttvv33L9a5ZswbZ2dn429/+BkmS8NZbb+HBBx/E77//fstv8D/88AM2bNiAZ555Bq6urnj33Xfx0EMPITk5GU2bNgUAHDhwAEOGDIG/vz/mz58Pi8WCBQsWwNvbu0r7vX79euTl5WHSpElo2rQpEhMTsWTJEvzxxx9Yv369XV2LxYKIiAiEhoZi0aJF2LlzJ9555x20bdsWkyZNAiCHhAceeAA//PADnn76aXTu3BkbN25EVFRUldozZswYzJ8/H2vWrMFdd91lt+3//Oc/6N+/P1q2bIn09HR8+OGHGD16NCZMmIDs7Gx89NFHiIiIQGJiYrlTQbcyZ84cvPbaaxg2bBiGDRuG/fv34/7770dhYaFdvd9//x2bNm3CI488gtatWyM1NRXvvfceBg4ciOPHj6NZs2bo3LkzFixYgDlz5mDixIno378/AKBv374VblsIgb/85S/YtWsXnnrqKQQFBWHHjh34+9//jgsXLuCf//ynXf2qfC5q6vr16xg0aBDOnDmDKVOmoHXr1li/fj3GjRuHjIwMTJs2DQAQFxeH0aNHY/DgwXjzzTcBACdOnMCePXuUOvPmzUNMTAzGjx+PPn36ICsrC7/88gv279+P++6777baSY2YIKJyJk+eLG7832PgwIECgFixYkW5+nl5eeXK/va3vwmz2Szy8/OVsqioKNGqVSvl/dmzZwUA0bRpU3H16lWl/KuvvhIAxH//+1+lbO7cueXaBEAYjUZx5swZpezQoUMCgFiyZIlSFhkZKcxms7hw4YJSdvr0aWEwGMqtsyIV7V9MTIyQJEkkJSXZ7R8AsWDBAru6vXr1EsHBwcr7TZs2CQDirbfeUsqKi4tF//79BQCxatWqW7apd+/eokWLFsJisShl27dvFwDEe++9p6yzoKDAbrlr164JX19f8eSTT9qVAxBz585V3q9atUoAEGfPnhVCCJGWliaMRqMYPny4sFqtSr2XX35ZABBRUVFKWX5+vl27hJB/1yaTye7Y7N2796b7e+NnxXbMXnvtNbt6Dz/8sJAkye4zUNXPRUVsn8m33377pnViY2MFAPHZZ58pZYWFhSIsLEy4uLiIrKwsIYQQ06ZNE25ubqK4uPim6+rZs6cYPnx4pW0iqi6eliKqBpPJhOjo6HLlTk5Oys/Z2dlIT09H//79kZeXh19//fWW6x01ahQ8PT2V97Zv8b///vstlw0PD0fbtm2V9z169ICbm5uyrMViwc6dOzFixAg0a9ZMqdeuXTsMHTr0lusH7PcvNzcX6enp6Nu3L4QQOHDgQLn6Tz/9tN37/v372+3L1q1bYTAYlJ4cQB7jMnXq1Cq1B5DHSf3xxx/47rvvlLI1a9bAaDTikUceUdZpNBoBAFarFVevXkVxcTFCQkIqPKVVmZ07d6KwsBBTp061O5X33HPPlatrMpmg08n/vFosFly5cgUuLi7o2LFjtbdrs3XrVuj1ejz77LN25S+88AKEENi2bZtd+a0+F7dj69at8PPzw+jRo5UyBwcHPPvss8jJycG3334LAPDw8EBubm6lp5g8PDxw7NgxnD59+rbbRWTDcENUDc2bN1f+WJZ17NgxjBw5Eu7u7nBzc4O3t7cyGDkzM/OW623ZsqXde1vQuXbtWrWXtS1vWzYtLQ3Xr19Hu3btytWrqKwiycnJGDduHJo0aaKMoxk4cCCA8vvn6OhY7nRX2fYAQFJSEvz9/eHi4mJXr2PHjlVqDwA89thj0Ov1WLNmDQAgPz8fGzduxNChQ+2C4scff4wePXoo4zm8vb2xZcuWKv1eykpKSgIAtG/f3q7c29vbbnuAHKT++c9/on379jCZTPDy8oK3tzcOHz5c7e2W3X6zZs3g6upqV267gs/WPptbfS5uR1JSEtq3b68EuJu15ZlnnkGHDh0wdOhQtGjRAk8++WS5cT8LFixARkYGOnTogO7du+Pvf/97vb+En+o/hhuiaijbg2GTkZGBgQMH4tChQ1iwYAH++9//Ii4uThljUJXLeW92VY64YaCo2stWhcViwX333YctW7bgxRdfxKZNmxAXF6cMfL1x/+rqCiMfHx/cd999+L//+z8UFRXhv//9L7KzszFmzBilzmeffYZx48ahbdu2+Oijj7B9+3bExcXh3nvvrdXLrBcuXIjp06djwIAB+Oyzz7Bjxw7ExcWha9eudXZ5d21/LqrCx8cHBw8exObNm5XxQkOHDrUbWzVgwAD89ttvWLlyJbp164YPP/wQd911Fz788MM6ayc1PBxQTHSbdu/ejStXrmDDhg0YMGCAUn727FkNW1XKx8cHjo6OFd70rrIb4dkcOXIEp06dwscff4yxY8cq5bdzNUurVq0QHx+PnJwcu96bkydPVms9Y8aMwfbt27Ft2zasWbMGbm5uiIyMVOZ/+eWXaNOmDTZs2GB3Kmnu3Lk1ajMAnD59Gm3atFHKL1++XK435Msvv8Q999yDjz76yK48IyMDXl5eyvvq3HG6VatW2LlzJ7Kzs+16b2ynPW3tqwutWrXC4cOHYbVa7XpvKmqL0WhEZGQkIiMjYbVa8cwzz+C9997D7NmzlZ7DJk2aIDo6GtHR0cjJycGAAQMwb948jB8/vs72iRoW9twQ3SbbN+Sy34gLCwvx73//W6sm2dHr9QgPD8emTZtw8eJFpfzMmTPlxmncbHnAfv+EEHaX81bXsGHDUFxcjOXLlytlFosFS5YsqdZ6RowYAbPZjH//+9/Ytm0bHnzwQTg6Olba9p9//hkJCQnVbnN4eDgcHBywZMkSu/XFxsaWq6vX68v1kKxfvx4XLlywK3N2dgaAKl0CP2zYMFgsFixdutSu/J///CckSary+Ck1DBs2DCkpKVi3bp1SVlxcjCVLlsDFxUU5ZXnlyhW75XQ6nXJjxYKCggrruLi4oF27dsp8oppgzw3Rberbty88PT0RFRWlPBrg008/rdPu/1uZN28evvnmG/Tr1w+TJk1S/kh269btlrf+79SpE9q2bYsZM2bgwoULcHNzw//93//d1tiNyMhI9OvXDy+99BLOnTuHLl26YMOGDdUej+Li4oIRI0Yo427KnpICgD//+c/YsGEDRo4cieHDh+Ps2bNYsWIFunTpgpycnGpty3a/npiYGPz5z3/GsGHDcODAAWzbts2uN8a23QULFiA6Ohp9+/bFkSNH8Pnnn9v1+ABA27Zt4eHhgRUrVsDV1RXOzs4IDQ1F69aty20/MjIS99xzD2bNmoVz586hZ8+e+Oabb/DVV1/hueeesxs8rIb4+Hjk5+eXKx8xYgQmTpyI9957D+PGjcO+ffsQGBiIL7/8Env27EFsbKzSszR+/HhcvXoV9957L1q0aIGkpCQsWbIEQUFByvicLl26YNCgQQgODkaTJk3wyy+/4Msvv8SUKVNU3R9qZLS5SIuofrvZpeBdu3atsP6ePXvEn/70J+Hk5CSaNWsm/vGPf4gdO3YIAGLXrl1KvZtdCl7RZbe44dLkm10KPnny5HLLtmrVyu7SZCGEiI+PF7169RJGo1G0bdtWfPjhh+KFF14Qjo6ONzkKpY4fPy7Cw8OFi4uL8PLyEhMmTFAuLS57GXNUVJRwdnYut3xFbb9y5Yp44oknhJubm3B3dxdPPPGEOHDgQJUvBbfZsmWLACD8/f3LXX5ttVrFwoULRatWrYTJZBK9evUSX3/9dbnfgxC3vhRcCCEsFouYP3++8Pf3F05OTmLQoEHi6NGj5Y53fn6+eOGFF5R6/fr1EwkJCWLgwIFi4MCBdtv96quvRJcuXZTL8m37XlEbs7OzxfPPPy+aNWsmHBwcRPv27cXbb79td2m6bV+q+rm4ke0zebPp008/FUIIkZqaKqKjo4WXl5cwGo2ie/fu5X5vX375pbj//vuFj4+PMBqNomXLluJvf/ubuHTpklLntddeE3369BEeHh7CyclJdOrUSbz++uuisLCw0nYSVUYSoh59vSSiOjVixAhehktEDQ7H3BA1Ejc+KuH06dPYunUrBg0apE2DiIhqCXtuiBoJf39/jBs3Dm3atEFSUhKWL1+OgoICHDhwoNy9W4iI7mQcUEzUSAwZMgRffPEFUlJSYDKZEBYWhoULFzLYEFGDw54bIiIialA45oaIiIgaFIYbIiIialAa3Zgbq9WKixcvwtXVtVq3PiciIiLtCCGQnZ2NZs2alXto640aXbi5ePEiAgICtG4GERER1cD58+fRokWLSus0unBjuy34+fPn4ebmpnFriIiIqCqysrIQEBBg9+DYm2l04cZ2KsrNzY3hhoiI6A5TlSElHFBMREREDQrDDRERETUoDDdERETUoDS6MTdERHT7LBYLioqKtG4GNTBGo/GWl3lXBcMNERFVmRACKSkpyMjI0Lop1ADpdDq0bt0aRqPxttbDcENERFVmCzY+Pj4wm828GSqpxnaT3UuXLqFly5a39dliuCEioiqxWCxKsGnatKnWzaEGyNvbGxcvXkRxcTEcHBxqvB4OKCYioiqxjbExm80at4QaKtvpKIvFclvrYbghIqJq4akoqi1qfbYYboiIiKhBYbghIiKqpsDAQMTGxla5/u7duyFJEq8yqyMMN0RE1GBJklTpNG/evBqtd+/evZg4cWKV6/ft2xeXLl2Cu7t7jbZXVQxRMl4tpZKCYgsuZxfAoNPBz91R6+YQERGAS5cuKT+vW7cOc+bMwcmTJ5UyFxcX5WchBCwWCwyGW/9p9Pb2rlY7jEYj/Pz8qrUM1Rx7blRy9EIW7n5zFx59L0HrphARUQk/Pz9lcnd3hyRJyvtff/0Vrq6u2LZtG4KDg2EymfDDDz/gt99+wwMPPABfX1+4uLigd+/e2Llzp916bzwtJUkSPvzwQ4wcORJmsxnt27fH5s2blfk39qisXr0aHh4e2LFjBzp37gwXFxcMGTLELowVFxfj2WefhYeHB5o2bYoXX3wRUVFRGDFiRI2Px7Vr1zB27Fh4enrCbDZj6NChOH36tDI/KSkJkZGR8PT0hLOzM7p27YqtW7cqy44ZMwbe3t5wcnJC+/btsWrVqhq3pTYx3KhMQGjdBCKiOiGEQF5hsSaTEOr9W/vSSy/hjTfewIkTJ9CjRw/k5ORg2LBhiI+Px4EDBzBkyBBERkYiOTm50vXMnz8fjz76KA4fPoxhw4ZhzJgxuHr16k3r5+XlYdGiRfj000/x3XffITk5GTNmzFDmv/nmm/j888+xatUq7NmzB1lZWdi0adNt7eu4cePwyy+/YPPmzUhISIAQAsOGDVMu8588eTIKCgrw3Xff4ciRI3jzzTeV3q3Zs2fj+PHj2LZtG06cOIHly5fDy8vrttpTW3haSiW2q9dU/P+NiKheu15kQZc5OzTZ9vEFETAb1fkTtmDBAtx3333K+yZNmqBnz57K+1dffRUbN27E5s2bMWXKlJuuZ9y4cRg9ejQAYOHChXj33XeRmJiIIUOGVFi/qKgIK1asQNu2bQEAU6ZMwYIFC5T5S5YswcyZMzFy5EgAwNKlS5VelJo4ffo0Nm/ejD179qBv374AgM8//xwBAQHYtGkTHnnkESQnJ+Ohhx5C9+7dAQBt2rRRlk9OTkavXr0QEhICQO69qq/Yc6MS25X5DDdERHcW2x9rm5ycHMyYMQOdO3eGh4cHXFxccOLEiVv23PTo0UP52dnZGW5ubkhLS7tpfbPZrAQbAPD391fqZ2ZmIjU1FX369FHm6/V6BAcHV2vfyjpx4gQMBgNCQ0OVsqZNm6Jjx444ceIEAODZZ5/Fa6+9hn79+mHu3Lk4fPiwUnfSpElYu3YtgoKC8I9//AM//vhjjdtS29hzoxLe1IqIGhsnBz2OL4jQbNtqcXZ2tns/Y8YMxMXFYdGiRWjXrh2cnJzw8MMPo7CwsNL13Pi4AEmSYLVaq1VfzdNtNTF+/HhERERgy5Yt+OabbxATE4N33nkHU6dOxdChQ5GUlIStW7ciLi4OgwcPxuTJk7Fo0SJN21wR9twQEVGNSJIEs9GgyVSbXyj37NmDcePGYeTIkejevTv8/Pxw7ty5WtteRdzd3eHr64u9e/cqZRaLBfv376/xOjt37ozi4mL8/PPPStmVK1dw8uRJdOnSRSkLCAjA008/jQ0bNuCFF17ABx98oMzz9vZGVFQUPvvsM8TGxuL999+vcXtqE3tuVFJ6WornpYiI7mTt27fHhg0bEBkZCUmSMHv27Ep7YGrL1KlTERMTg3bt2qFTp05YsmQJrl27VqVgd+TIEbi6uirvJUlCz5498cADD2DChAl477334OrqipdeegnNmzfHAw88AAB47rnnMHToUHTo0AHXrl3Drl270LlzZwDAnDlzEBwcjK5du6KgoABff/21Mq++0bznZtmyZQgMDISjoyNCQ0ORmJhYaf3Y2Fh07NgRTk5OCAgIwPPPP4/8/Pw6au3NKQOKtW0GERHdpsWLF8PT0xN9+/ZFZGQkIiIicNddd9V5O1588UWMHj0aY8eORVhYGFxcXBAREQFHx1vfS23AgAHo1auXMtnG6qxatQrBwcH485//jLCwMAghsHXrVuUUmcViweTJk9G5c2cMGTIEHTp0wL///W8A8r16Zs6ciR49emDAgAHQ6/VYu3Zt7R2A2yAJDbsa1q1bh7Fjx2LFihUIDQ1FbGws1q9fj5MnT8LHx6dc/TVr1uDJJ5/EypUr0bdvX5w6dQrjxo3DY489hsWLF1dpm1lZWXB3d0dmZibc3NxU25cjf2QicukP8HNzxE8vD1ZtvURE9UV+fj7Onj2L1q1bV+kPLKnLarWic+fOePTRR/Hqq69q3ZxaUdlnrDp/vzXtuVm8eDEmTJiA6OhodOnSBStWrIDZbMbKlSsrrP/jjz+iX79+ePzxxxEYGIj7778fo0ePvmVvT13geGIiIlJTUlISPvjgA5w6dQpHjhzBpEmTcPbsWTz++ONaN63e0yzcFBYWYt++fQgPDy9tjE6H8PBwJCRUfJffvn37Yt++fUqY+f3337F161YMGzbsptspKChAVlaW3VSbeBM/IiJSg06nw+rVq9G7d2/069cPR44cwc6dO+vtOJf6RLMBxenp6bBYLPD19bUr9/X1xa+//lrhMo8//jjS09Nx9913QwiB4uJiPP3003j55Zdvup2YmBjMnz9f1bZXhuOJiYhIDQEBAdizZ4/WzbgjaT6guDp2796NhQsX4t///jf279+PDRs2YMuWLZWee5w5cyYyMzOV6fz587XSNg4oJiIiqh8067nx8vKCXq9HamqqXXlqaupNn5w6e/ZsPPHEExg/fjwAoHv37sjNzcXEiRMxa9Ys6HTls5rJZILJZFJ/B24ggYNuiIiI6gPNem6MRiOCg4MRHx+vlFmtVsTHxyMsLKzCZfLy8soFGL1evktlfbm/TD1pBhERUaOl6U38pk+fjqioKISEhKBPnz6IjY1Fbm4uoqOjAQBjx45F8+bNERMTAwCIjIzE4sWL0atXL4SGhuLMmTOYPXs2IiMjlZCjldKrpZhuiIiItKRpuBk1ahQuX76MOXPmICUlBUFBQdi+fbsyyDg5Odmup+aVV16BJEl45ZVXcOHCBXh7eyMyMhKvv/66Vrug4FPBiYiI6gdNb+Knhdq6id/JlGxExH6HJs5G7J99n2rrJSKqL3gTP6ptDeImfg0Jb+JHRNRwDRo0CM8995zyPjAwELGxsZUuI0kSNm3adNvbVms9jQnDjcoaWUcYEVG9FhkZiSFDhlQ47/vvv4ckSTh8+HC117t3715MnDjxdptnZ968eQgKCipXfunSJQwdOlTVbd1o9erV8PDwqNVt1CWGG5UoTwXXtBVERFTWU089hbi4OPzxxx/l5q1atQohISHo0aNHtdfr7e0Ns9msRhNvyc/Pr05uadKQMNyohAOKiYjqnz//+c/w9vbG6tWr7cpzcnKwfv16PPXUU7hy5QpGjx6N5s2bw2w2o3v37vjiiy8qXe+Np6VOnz6NAQMGwNHREV26dEFcXFy5ZV588UV06NABZrMZbdq0wezZs1FUVARA7jmZP38+Dh06BEmSIEmS0uYbT0sdOXIE9957L5ycnNC0aVNMnDgROTk5yvxx48ZhxIgRWLRoEfz9/dG0aVNMnjxZ2VZNJCcn44EHHoCLiwvc3Nzw6KOP2t2n7tChQ7jnnnvg6uoKNzc3BAcH45dffgEgPyMrMjISnp6ecHZ2RteuXbF169Yat6UqNL1aqmHhoBsiamSEAIrytNm2g7lKgx0NBgPGjh2L1atXY9asWZBKllm/fj0sFgtGjx6NnJwcBAcH48UXX4Sbmxu2bNmCJ554Am3btkWfPn1uuQ2r1YoHH3wQvr6++Pnnn5GZmWk3PsfG1dUVq1evRrNmzXDkyBFMmDABrq6u+Mc//oFRo0bh6NGj2L59O3bu3AkAcHd3L7eO3NxcREREICwsDHv37kVaWhrGjx+PKVOm2AW4Xbt2wd/fH7t27cKZM2cwatQoBAUFYcKECbfcn4r2zxZsvv32WxQXF2Py5MkYNWoUdu/eDQAYM2YMevXqheXLl0Ov1+PgwYNwcHAAAEyePBmFhYX47rvv4OzsjOPHj8PFxaXa7agOhhuVccwNETUaRXnAwmbabPvli4DRuUpVn3zySbz99tv49ttvMWjQIADyKamHHnoI7u7ucHd3x4wZM5T6U6dOxY4dO/Cf//ynSuFm586d+PXXX7Fjxw40ayYfj4ULF5YbJ/PKK68oPwcGBmLGjBlYu3Yt/vGPf8DJyQkuLi4wGAw3vUs/AKxZswb5+fn45JNP4Ows7//SpUsRGRmJN998U7mViqenJ5YuXQq9Xo9OnTph+PDhiI+Pr1G4iY+Px5EjR3D27FkEBAQAAD755BN07doVe/fuRe/evZGcnIy///3v6NSpEwCgffv2yvLJycl46KGH0L17dwBAmzZtqt2G6uJpKZXw2VJERPVTp06d0LdvX6xcuRIAcObMGXz//fd46qmnAAAWiwWvvvoqunfvjiZNmsDFxQU7duxAcnJyldZ/4sQJBAQEKMEGQIV32l+3bh369esHPz8/uLi44JVXXqnyNspuq2fPnkqwAYB+/frBarXi5MmTSlnXrl3tbm7r7++PtLS0am2r7DYDAgKUYAMAXbp0gYeHB06cOAFAvinv+PHjER4ejjfeeAO//fabUvfZZ5/Fa6+9hn79+mHu3Lk1GsBdXey5UQlvUExEjY6DWe5B0Wrb1fDUU09h6tSpWLZsGVatWoW2bdti4MCBAIC3334b//rXvxAbG4vu3bvD2dkZzz33HAoLC1VrbkJCAsaMGYP58+cjIiIC7u7uWLt2Ld555x3VtlGW7ZSQjSRJsFqttbItQL7S6/HHH8eWLVuwbds2zJ07F2vXrsXIkSMxfvx4REREYMuWLfjmm28QExODd955B1OnTq219rDnRiUSb3RDRI2NJMmnhrSYqvlv7qOPPgqdToc1a9bgk08+wZNPPqn8u71nzx488MAD+Otf/4qePXuiTZs2OHXqVJXX3blzZ5w/fx6XLl1Syn766Se7Oj/++CNatWqFWbNmISQkBO3bt0dSUpJdHaPRCIvFcsttHTp0CLm5uUrZnj17oNPp0LFjxyq3uTps+3f+/Hml7Pjx48jIyECXLl2Usg4dOuD555/HN998gwcffBCrVq1S5gUEBODpp5/Ghg0b8MILL+CDDz6olbbaMNyojB03RET1j4uLC0aNGoWZM2fi0qVLGDdunDKvffv2iIuLw48//ogTJ07gb3/7m92VQLcSHh6ODh06ICoqCocOHcL333+PWbNm2dVp3749kpOTsXbtWvz222949913sXHjRrs6gYGBOHv2LA4ePIj09HQUFBSU29aYMWPg6OiIqKgoHD16FLt27cLUqVPxxBNPKONtaspiseDgwYN204kTJxAeHo7u3btjzJgx2L9/PxITEzF27FgMHDgQISEhuH79OqZMmYLdu3cjKSkJe/bswd69e9G5c2cAwHPPPYcdO3bg7Nmz2L9/P3bt2qXMqy0MNypR7nPDAcVERPXSU089hWvXriEiIsJufMwrr7yCu+66CxERERg0aBD8/PwwYsSIKq9Xp9Nh48aNuH79Ovr06YPx48eXe+bhX/7yFzz//POYMmUKgoKC8OOPP2L27Nl2dR566CEMGTIE99xzD7y9vSu8HN1sNmPHjh24evUqevfujYcffhiDBw/G0qVLq3cwKpCTk4NevXrZTZGRkZAkCV999RU8PT0xYMAAhIeHo02bNli3bh0AQK/X48qVKxg7diw6dOiARx99FEOHDsX8+fMByKFp8uTJ6Ny5M4YMGYIOHTrg3//+9223tzJ8tpRKkq7kYuDbu2E26nF8QcV3wyQiupPx2VJU2/hsqXpGKum7aVxRkYiIqP5huFEJxxMTERHVDww3KhMcUkxERKQphhuV8bQUERGRthhuVMI7FBNRY9HIrkOhOqTWZ4vhRiW8iR8RNXS2u97m5Wn0sExq8Gx3hS776Iia4OMX1MYvNETUQOn1enh4eCjPKDKbzfxiR6qxWq24fPkyzGYzDIbbiycMNypRbuLHdENEDZjtidU1fQgjUWV0Oh1atmx526GZ4UYlypgbZhsiasAkSYK/vz98fHxQVFSkdXOogTEajdDpbn/EDMONSpSb+GncDiKiuqDX6297XARRbeGAYpXwtDMREVH9wHCjMl4iSUREpC2GG5WUDigmIiIiLTHcqIUDiomIiOoFhhuVSOCgGyIiovqA4YaIiIgaFIYblZS9WoqDiomIiLTDcKOSsielmG2IiIi0Uy/CzbJlyxAYGAhHR0eEhoYiMTHxpnUHDRoESZLKTcOHD6/DFpfH56sQERHVD5qHm3Xr1mH69OmYO3cu9u/fj549eyIiIuKmzy3ZsGEDLl26pExHjx6FXq/HI488Usctvzl23BAREWlH83CzePFiTJgwAdHR0ejSpQtWrFgBs9mMlStXVli/SZMm8PPzU6a4uDiYzWbNw439aSnGGyIiIq1oGm4KCwuxb98+hIeHK2U6nQ7h4eFISEio0jo++ugjPPbYY3B2dq5wfkFBAbKysuym2mA3oLhWtkBERERVoWm4SU9Ph8Viga+vr125r68vUlJSbrl8YmIijh49ivHjx9+0TkxMDNzd3ZUpICDgtttdkbL3uWHHDRERkXY0Py11Oz766CN0794dffr0uWmdmTNnIjMzU5nOnz9fO43heGIiIqJ6waDlxr28vKDX65GammpXnpqaCj8/v0qXzc3Nxdq1a7FgwYJK65lMJphMpttua3UInpgiIiLSjKY9N0ajEcHBwYiPj1fKrFYr4uPjERYWVumy69evR0FBAf7617/WdjOrxP4mftq1g4iIqLHTtOcGAKZPn46oqCiEhISgT58+iI2NRW5uLqKjowEAY8eORfPmzRETE2O33EcffYQRI0agadOmWjS7HJ6VIiIiqh80DzejRo3C5cuXMWfOHKSkpCAoKAjbt29XBhknJydDp7PvYDp58iR++OEHfPPNN1o0uUK8iR8REVH9IIlGdlOWrKwsuLu7IzMzE25ubqqtN6egGN3m7gAAnFgwBE5GvWrrJiIiauyq8/f7jr5aqj6xu4kfBxQTERFphuFGJRxQTEREVD8w3KjE7iZ+GraDiIiosWO4UQnHExMREdUPDDe1oJGN0SYiIqpXGG5qAaMNERGRdhhuVMIBxURERPUDw41KJN6jmIiIqF5guKkN7LkhIiLSDMONSuxOSzHdEBERaYbhRiV2dyhmtiEiItIMw41Kyj44k9mGiIhIOww3KuFwYiIiovqB4aYW8CZ+RERE2mG4UYn9gGIiIiLSCsONSuzG3DDdEBERaYbhhoiIiBoUhptawPvcEBERaYfhRkXKmSlmGyIiIs0w3KiI2YaIiEh7DDcqKjuomIiIiLTBcFMLeLUUERGRdhhuVFR6WorphoiISCsMNyqynZVizw0REZF2GG5UJJX03TDbEBERaYfhRk0cT0xERKQ5hptawAdnEhERaYfhRkXKgGJmGyIiIs0w3KiIt7khIiLSHsONiiQOuiEiItIcw00t4GkpIiIi7WgebpYtW4bAwEA4OjoiNDQUiYmJldbPyMjA5MmT4e/vD5PJhA4dOmDr1q111NrKKfe54cXgREREmjFoufF169Zh+vTpWLFiBUJDQxEbG4uIiAicPHkSPj4+5eoXFhbivvvug4+PD7788ks0b94cSUlJ8PDwqPvGV4ADiomIiLSnabhZvHgxJkyYgOjoaADAihUrsGXLFqxcuRIvvfRSuforV67E1atX8eOPP8LBwQEAEBgYWJdNrpTtwZnMNkRERNrR7LRUYWEh9u3bh/Dw8NLG6HQIDw9HQkJChcts3rwZYWFhmDx5Mnx9fdGtWzcsXLgQFovlptspKChAVlaW3VRbOJyYiIhIe5qFm/T0dFgsFvj6+tqV+/r6IiUlpcJlfv/9d3z55ZewWCzYunUrZs+ejXfeeQevvfbaTbcTExMDd3d3ZQoICFB1PyrCm/gRERFpR/MBxdVhtVrh4+OD999/H8HBwRg1ahRmzZqFFStW3HSZmTNnIjMzU5nOnz9few1UBhQTERGRVjQbc+Pl5QW9Xo/U1FS78tTUVPj5+VW4jL+/PxwcHKDX65Wyzp07IyUlBYWFhTAajeWWMZlMMJlM6jb+JjigmIiISHua9dwYjUYEBwcjPj5eKbNarYiPj0dYWFiFy/Tr1w9nzpyB1WpVyk6dOgV/f/8Kg01dk3iLYiIiIs1pelpq+vTp+OCDD/Dxxx/jxIkTmDRpEnJzc5Wrp8aOHYuZM2cq9SdNmoSrV69i2rRpOHXqFLZs2YKFCxdi8uTJWu3CTbDrhoiISCuaXgo+atQoXL58GXPmzEFKSgqCgoKwfft2ZZBxcnIydLrS/BUQEIAdO3bg+eefR48ePdC8eXNMmzYNL774ola7YEe5iR+zDRERkWYk0cgu7cnKyoK7uzsyMzPh5uam6rp7LfgG1/KK8M3zA9DB11XVdRMRETVm1fn7fUddLVXfccwNERGR9hhuakHj6gsjIiKqXxhuVKRcCs4BxURERJphuFERBxQTERFpj+FGVSUPzmS4ISIi0gzDjYo4npiIiEh7DDe1gGNuiIiItMNwoyI+W4qIiEh7DDcq4mkpIiIi7THcqEgC0w0REZHWGG5qAU9LERERaYfhRkXKfW44oJiIiEgzDDcq4oBiIiIi7THcqMj24ExmGyIiIu0w3BAREVGDwnBTCwTPSxEREWmG4UZFpQOKiYiISCsMNyriU8GJiIi0x3CjIt7Ej4iISHsMN7WCXTdERERaYbhREU9LERERaY/hRkXKTfw0bQUREVHjxnCjIuUmfkw3REREmmG4ISIiogaF4UZFpc+WYtcNERGRVhhu1MSb+BEREWmO4UZFfCo4ERGR9hhuVGQbUExERETaYbipBYInpoiIiDTDcKMipd+G2YaIiEgz9SLcLFu2DIGBgXB0dERoaCgSExNvWnf16tWQJMlucnR0rMPW3hyfCk5ERKQ9zcPNunXrMH36dMydOxf79+9Hz549ERERgbS0tJsu4+bmhkuXLilTUlJSHbb45vjgTCIiIu1pHm4WL16MCRMmIDo6Gl26dMGKFStgNpuxcuXKmy4jSRL8/PyUydfXtw5bfGu8WoqIiEg7moabwsJC7Nu3D+Hh4UqZTqdDeHg4EhISbrpcTk4OWrVqhYCAADzwwAM4duzYTesWFBQgKyvLbqotpaelmG6IiIi0omm4SU9Ph8ViKdfz4uvri5SUlAqX6dixI1auXImvvvoKn332GaxWK/r27Ys//vijwvoxMTFwd3dXpoCAANX340bsuSEiItKO5qelqissLAxjx45FUFAQBg4ciA0bNsDb2xvvvfdehfVnzpyJzMxMZTp//nyttU15cGatbYGIiIhuxaDlxr28vKDX65GammpXnpqaCj8/vyqtw8HBAb169cKZM2cqnG8ymWAymW67rVXB4cRERETa07Tnxmg0Ijg4GPHx8UqZ1WpFfHw8wsLCqrQOi8WCI0eOwN/fv7aaWW18cCYREZF2NO25AYDp06cjKioKISEh6NOnD2JjY5Gbm4vo6GgAwNixY9G8eXPExMQAABYsWIA//elPaNeuHTIyMvD2228jKSkJ48eP13I3APA+N0RERPWB5uFm1KhRuHz5MubMmYOUlBQEBQVh+/btyiDj5ORk6HSlHUzXrl3DhAkTkJKSAk9PTwQHB+PHH39Ely5dtNoFhfJoKaYbIiIizUiikZ1DycrKgru7OzIzM+Hm5qbquiOX/IAjFzKxalxv3NPJR9V1ExERNWbV+ft9x10tdSfgfW6IiIi0w3CjImXMDbMNERGRZhhuVKQMuWG4ISIi0gzDjZp4Ez8iIiLNMdyoiDfxIyIi0h7DTS1oZBegERER1SsMNyriTfyIiIi0x3CjIg4oJiIi0h7DjYokiaNuiIiItMZwUyvYdUNERKQVhhsV8bQUERGR9hhuVMQBxURERNpjuFGRxDvdEBERaY7hphbwtBQREZF2GG7UpJyWYrohIiLSSo3Czfnz5/HHH38o7xMTE/Hcc8/h/fffV61hdyIOKCYiItJejcLN448/jl27dgEAUlJScN999yExMRGzZs3CggULVG3gnYQDiomIiLRXo3Bz9OhR9OnTBwDwn//8B926dcOPP/6Izz//HKtXr1azfXcUDigmIiLSXo3CTVFREUwmEwBg586d+Mtf/gIA6NSpEy5duqRe6+5QfHAmERGRdmoUbrp27YoVK1bg+++/R1xcHIYMGQIAuHjxIpo2bapqA+8kfPoCERGR9moUbt5880289957GDRoEEaPHo2ePXsCADZv3qycrmqMlDE37LghIiLSjKEmCw0aNAjp6enIysqCp6enUj5x4kSYzWbVGnen4ZgbIiIi7dWo5+b69esoKChQgk1SUhJiY2Nx8uRJ+Pj4qNrAOxHvc0NERKSdGoWbBx54AJ988gkAICMjA6GhoXjnnXcwYsQILF++XNUG3kl4WoqIiEh7NQo3+/fvR//+/QEAX375JXx9fZGUlIRPPvkE7777rqoNvBMx3BAREWmnRuEmLy8Prq6uAIBvvvkGDz74IHQ6Hf70pz8hKSlJ1QbeSaSSrhtmGyIiIu3UKNy0a9cOmzZtwvnz57Fjxw7cf//9AIC0tDS4ubmp2sA7CYcTExERaa9G4WbOnDmYMWMGAgMD0adPH4SFhQGQe3F69eqlagPvRLyJHxERkXZqdCn4ww8/jLvvvhuXLl1S7nEDAIMHD8bIkSNVa9ydhs+WIiIi0l6Nwg0A+Pn5wc/PT3k6eIsWLRr1DfyAMqelmG6IiIg0U6PTUlarFQsWLIC7uztatWqFVq1awcPDA6+++iqsVqvabbxjSHz+AhERkeZqFG5mzZqFpUuX4o033sCBAwdw4MABLFy4EEuWLMHs2bOrvb5ly5YhMDAQjo6OCA0NRWJiYpWWW7t2LSRJwogRI6q9zdrEm/gRERFpp0anpT7++GN8+OGHytPAAaBHjx5o3rw5nnnmGbz++utVXte6deswffp0rFixAqGhoYiNjUVERMQt73Z87tw5zJgxQ7nfTn1g67fheGIiIiLt1Kjn5urVq+jUqVO58k6dOuHq1avVWtfixYsxYcIEREdHo0uXLlixYgXMZjNWrlx502UsFgvGjBmD+fPno02bNtVuf23hgGIiIiLt1Sjc9OzZE0uXLi1XvnTpUvTo0aPK6yksLMS+ffsQHh5e2iCdDuHh4UhISLjpcgsWLICPjw+eeuqpW26joKAAWVlZdlPtKbmJH9MNERGRZmp0Wuqtt97C8OHDsXPnTuUeNwkJCTh//jy2bt1a5fWkp6fDYrHA19fXrtzX1xe//vprhcv88MMP+Oijj3Dw4MEqbSMmJgbz58+vcpuIiIjozlajnpuBAwfi1KlTGDlyJDIyMpCRkYEHH3wQx44dw6effqp2GxXZ2dl44okn8MEHH8DLy6tKy8ycOROZmZnKdP78+VprX+lpKXbdEBERaaXG97lp1qxZuYHDhw4dwkcffYT333+/Suvw8vKCXq9HamqqXXlqair8/PzK1f/tt99w7tw5REZGKmW2S88NBgNOnjyJtm3b2i1jMplgMpmq1J7bxQHFRERE2qtRz41ajEYjgoODER8fr5RZrVbEx8crp7vK6tSpE44cOYKDBw8q01/+8hfcc889OHjwIAICAuqy+eVwQDEREZH2atxzo5bp06cjKioKISEh6NOnD2JjY5Gbm4vo6GgAwNixY9G8eXPExMTA0dER3bp1s1vew8MDAMqVa0HiozOJiIg0p3m4GTVqFC5fvow5c+YgJSUFQUFB2L59uzLIODk5GTqdph1M1cfzUkRERJqpVrh58MEHK52fkZFRo0ZMmTIFU6ZMqXDe7t27K1129erVNdpmbeBpKSIiIu1VK9y4u7vfcv7YsWNvq0F3MiXcMN0QERFpplrhZtWqVbXVjgaBY26IiIi0d4cNZrkzCHbdEBERaYbhRk0cc0NERKQ5hhsV8SZ+RERE2mO4UZFUMqKY2YaIiEg7DDcq4nBiIiIi7THc1AIOKCYiItIOw42KJHbdEBERaY7hRkUcUExERKQ9hhsVSey6ISIi0hzDTS0QvF6KiIhIMww3KuJpKSIiIu0x3KiJdygmIiLSHMONimwPzmTPDRERkXYYblTE8cRERETaY7ipBRxQTEREpB2GGxVxQDEREZH2GG5UxNNSRERE2mO4UZHER2cSERFpjuGmFvDBmURERNphuFGR7bQUsw0REZF2GG5UJPEmfkRERJpjuFEVx9wQERFpjeGmFvC0FBERkXYYblRUelqK6YaIiEgrDDcq4k38iIiItMdwoyIOKCYiItIew42KeBM/IiIi7THc1AaelyIiItJMvQg3y5YtQ2BgIBwdHREaGorExMSb1t2wYQNCQkLg4eEBZ2dnBAUF4dNPP63D1t4cT0sRERFpT/Nws27dOkyfPh1z587F/v370bNnT0RERCAtLa3C+k2aNMGsWbOQkJCAw4cPIzo6GtHR0dixY0cdt7w8DigmIiLSnubhZvHixZgwYQKio6PRpUsXrFixAmazGStXrqyw/qBBgzBy5Eh07twZbdu2xbRp09CjRw/88MMPddzy8nQ6Od5YmW6IiIg0o2m4KSwsxL59+xAeHq6U6XQ6hIeHIyEh4ZbLCyEQHx+PkydPYsCAARXWKSgoQFZWlt1UWwwl4cZiZbghIiLSiqbhJj09HRaLBb6+vnblvr6+SElJuelymZmZcHFxgdFoxPDhw7FkyRLcd999FdaNiYmBu7u7MgUEBKi6D2XZem6KGW6IiIg0o/lpqZpwdXXFwYMHsXfvXrz++uuYPn06du/eXWHdmTNnIjMzU5nOnz9fa+1izw0REZH2DFpu3MvLC3q9HqmpqXblqamp8PPzu+lyOp0O7dq1AwAEBQXhxIkTiImJwaBBg8rVNZlMMJlMqrb7ZvQSww0REZHWNO25MRqNCA4ORnx8vFJmtVoRHx+PsLCwKq/HarWioKCgNppYLXqdfDgtHFBMRESkGU17bgBg+vTpiIqKQkhICPr06YPY2Fjk5uYiOjoaADB27Fg0b94cMTExAOQxNCEhIWjbti0KCgqwdetWfPrpp1i+fLmWuwEAMOhLem4sDDdERERa0TzcjBo1CpcvX8acOXOQkpKCoKAgbN++XRlknJycDJ2utIMpNzcXzzzzDP744w84OTmhU6dO+OyzzzBq1CitdkGhkzigmIiISGuSEI3rHEpWVhbc3d2RmZkJNzc3Vdf9wXe/4/WtJzCyV3P8c1SQqusmIiJqzKrz9/uOvFqqvtLzUnAiIiLNMdyoSK9cCm7VuCVERESNF8ONivS8zw0REZHmGG5UxJv4ERERaY/hRkV8/AIREZH2GG5UxJ4bIiIi7THcqIhjboiIiLTHcKMihhsiIiLtMdyoiKeliIiItMdwoyLbgzM5oJiIiEg7DDcq0pccTWvjeqIFERFRvcJwoyKl54ZPBSciItIMw42KOOaGiIhIeww3KtJJJeGGp6WIiIg0w3CjIoOePTdERERaY7hRkV55/AKfCk5ERKQVhhsV6UtOSzHbEBERaYfhRkXsuSEiItIew42KSsfcaNwQIiKiRozhRkW201IW9twQERFphuFGRaWnpXi1FBERkVYYblRkCzdWhhsiIiLNMNyoiD03RERE2mO4UZGh5NlSvIkfERGRdhhuVFSSbfj4BSIiIg0x3KjI1nMjBMfdEBERaYXhRkW2MTcAe2+IiIi0wnCjIrtww54bIiIiTTDcqMhQJtzwiikiIiJtMNyoiD03RERE2mO4UZHt8QsAww0REZFW6kW4WbZsGQIDA+Ho6IjQ0FAkJibetO4HH3yA/v37w9PTE56enggPD6+0fl3S6STY8g2fDE5ERKQNzcPNunXrMH36dMydOxf79+9Hz549ERERgbS0tArr7969G6NHj8auXbuQkJCAgIAA3H///bhw4UIdt7xiBuURDBo3hIiIqJGShND2muXQ0FD07t0bS5cuBQBYrVYEBARg6tSpeOmll265vMVigaenJ5YuXYqxY8fesn5WVhbc3d2RmZkJNze3227/jTq+sg0FxVb88OI9aOFpVn39REREjVF1/n5r2nNTWFiIffv2ITw8XCnT6XQIDw9HQkJCldaRl5eHoqIiNGnSpML5BQUFyMrKsptqk63nhmNuiIiItKFpuElPT4fFYoGvr69dua+vL1JSUqq0jhdffBHNmjWzC0hlxcTEwN3dXZkCAgJuu92V0TPcEBERaUrzMTe344033sDatWuxceNGODo6Vlhn5syZyMzMVKbz58/XapsMevmQ8j43RERE2jBouXEvLy/o9XqkpqbalaempsLPz6/SZRctWoQ33ngDO3fuRI8ePW5az2QywWQyqdLeqjCWhJvCYo4oJiIi0oKmPTdGoxHBwcGIj49XyqxWK+Lj4xEWFnbT5d566y28+uqr2L59O0JCQuqiqVVmcpAPaUGxReOWEBERNU6a9twAwPTp0xEVFYWQkBD06dMHsbGxyM3NRXR0NABg7NixaN68OWJiYgAAb775JubMmYM1a9YgMDBQGZvj4uICFxcXzfbDxmQoCTdF7LkhIiLSgubhZtSoUbh8+TLmzJmDlJQUBAUFYfv27cog4+TkZOh0pR1My5cvR2FhIR5++GG79cydOxfz5s2ry6ZXyGTQAwAKLAw3REREWtA83ADAlClTMGXKlArn7d692+79uXPnar9Bt4E9N0RERNq6o6+Wqo845oaIiEhbDDcqs10tVcCrpYiIiDTBcKMyZcwNww0REZEmGG5UppyWKuJpKSIiIi0w3KhMGVDMnhsiIiJNMNyojKeliIiItMVwozJbzw0fv0BERKQNhhuV8VJwIiIibTHcqMyo52kpIiIiLTHcqKz0aimGGyIiIi0w3Kis9GopnpYiIiLSAsONyni1FBERkbYYblTG+9wQERFpi+FGZbxDMRERkbYYblRmOy1VaGHPDRERkRYYblRmOy11vZA9N0RERFpguFGZs0nuucljuCEiItIEw43KXEwOAIDcgmKNW0JERNQ4MdyozNZzk81wQ0REpAmGG5W5lvTcFBZb+fBMIiIiDTDcqMzWcwPw1BQREZEWGG5UZtDr4Fhyr5schhsiIqI6x3BTC1xMBgAMN0RERFpguKkFtnDD01JERER1j+GmFjiXhBteMUVERFT3GG5qAXtuiIiItMNwUwtcHUvG3OQz3BAREdU1hpta4MwBxURERJoxaN2ABiPtBLDrdcDcFO5OEwAAGXlFGjeKiIio8WHPjVoKc4ET/wV++x+aOBsBAFdyCzVuFBERUeOjebhZtmwZAgMD4ejoiNDQUCQmJt607rFjx/DQQw8hMDAQkiQhNja27hp6KyZX+bUgG01Lws3V3AING0RERNQ4aRpu1q1bh+nTp2Pu3LnYv38/evbsiYiICKSlpVVYPy8vD23atMEbb7wBPz+/Om7tLZQJN03MtnDDnhsiIqK6pmm4Wbx4MSZMmIDo6Gh06dIFK1asgNlsxsqVKyus37t3b7z99tt47LHHYDKZ6ri1t2ALN9ZieDkKADwtRUREpAXNwk1hYSH27duH8PDw0sbodAgPD0dCQoJq2ykoKEBWVpbdVCscnAFIAAAvo3w6ij03REREdU+zcJOeng6LxQJfX1+7cl9fX6SkpKi2nZiYGLi7uytTQECAauu2o9MpvTeeBjncZOQVodhirZ3tERERUYU0H1Bc22bOnInMzExlOn/+fO1trCTcuEv5kOROHFzNY+8NERFRXdLsPjdeXl7Q6/VITU21K09NTVV1sLDJZKq78Tkl4UZflA1vFxPSsguQkpkPH1fHutk+ERERaddzYzQaERwcjPj4eKXMarUiPj4eYWFhWjXr9pS5YqqFpxMA4I9r1zVsEBERUeOj6R2Kp0+fjqioKISEhKBPnz6IjY1Fbm4uoqOjAQBjx45F8+bNERMTA0AehHz8+HHl5wsXLuDgwYNwcXFBu3btNNsPRZlwE9CkGfYnZ+D81Txt20RERNTIaBpuRo0ahcuXL2POnDlISUlBUFAQtm/frgwyTk5Ohk5X2rl08eJF9OrVS3m/aNEiLFq0CAMHDsTu3bvruvnlseeGiIhIc5o/W2rKlCmYMmVKhfNuDCyBgYEQQtRBq2pICTdZaOFpBgCcv8aeGyIiorrU4K+WqlNmL/k16xJaezkDAE6n5mjYICIiosaH4UZNPl3k17Tj6NLMDQBwIeM6b+ZHRERUhxhu1ORbEm5Sj8LNZEBgU/nU1LGLmRo2ioiIqHFhuFGTVwdAZwDyM4FrZ9GjhQcA4Kffr2jbLiIiokaE4UZNBhPQsuQePQc+x+DOPgCAb46lVrIQERERqYnhRm19Jsiv+1ZjUFt3OOglnE7Lwd5zV7VtFxERUSPBcKO2jsMB12ZAXjrcf9uMh4PlB3XO/+8x5BdZNG4cERFRw8dwoza9AQidKP+8+w1MG9QKnmYHHL2Qhcc/+Aln0nhpOBERUW1iuKkNfSYCLr5ARhL8Tn+B98eGwNVkwP7kDAz913eY+9VRpGXna91KIiKiBonhpjYYnYGB/5B/jpuL3gWJ2DqtP+7p6I0ii8DHCUkY+NZuvLX9V2TmFWnbViIiogZGEvX6eQbqy8rKgru7OzIzM+Hm5lZ7G7JagC8eA05/I7/v9jAw4O/4McsLb+04iYPnMwAAbo4G/G1gW0T3C4TZqPnTMIiIiOql6vz9ZripTcUFwM75wE/LSgokoPvDEIPnIO6CEYu+OYlTJY9n8HIxYeq97TC6T0sYDexQIyIiKovhphJ1Gm5sLh4Evl8EnPiv/N7oAkS8DkvQE9h8+BIWx53C+avy08P93BzxaO8APBrSQnn4JhERUWPHcFMJTcKNzcWDwLYXgfM/ye+9OwP3zUdh63D8Z98feDf+NNKyC5TqfVo3wYig5hje3R/uZoe6bSsREVE9wnBTCU3DDSCPxflpOfDtW0BByTOn2t4LDH0b+e6tseNYCtYmnkdCmUc2GA063NfFFw/2ao6+bb3gZNTXfbuJiIg0xHBTCc3Djc31DOD7d4CfVwCWQsDgCAx6Ceg1FnBuiosZ17H50EVs3H8BJ1OzlcWMBh1CWzdB78Am6OLvhs7N3NDM3RGSJGm3L0RERLWM4aYS9Sbc2Fz9Hfh6OvD7rtIy325AQB8gIBSiZRiO5Xng//b/gW+OpeJCxvVyq3By0KNVUzPaeDujrbdLmVcXuJh4BRYREd35GG4qUe/CDQAIARxcAyQsBdKOl5/ftB3QdjBE23tx1twNu5OKcPRCJo5fysKZtBwUW2/+K/R1M6GNl4td8Gnu4QQfV0e4ORnY40NERHcEhptK1MtwU1ZOGpD0I/DHXiD5J+DiAUDc8EwqF1/APQBw8YHV7IUsvSdSre44JbVGQmFbnEnPw++Xc5GeU1DxNkoY9Tp4u5rg5WqCj6sJ3q4meLuY4OMmv3q7lk4mA8f5EBGRdhhuKlHvw82NrmcAZ78DfosHfvsfkJFceX0XP6DD/UDLvshu0g2/Wbzx29Vi/J6eg9/ScnE2PRcpWfnIvF69OyO7OznYhZ9WTcxo4+2i9AY58/QXERHVIoabStxx4eZG+VnAldNA1iUg97I85aQBWReBcz+UXoFlI+nkXp6m7UqnJm1Q6NQUV4QbUoudkZYHXM4pwOXsAqRly69lp0KL9ZbNaupshJuTA1wdDXAxGeDqaICro4Py6qaU28pKf3Z00MNk0MFk0PE0GRERVYjhphJ3fLipTHEhcPZbuacn+Sfg8q9AQdatlzO6AOamgLOX/OriK4cgr/YQTdsjy7EFLl+3IC2rAJdzCpCSmY9zV3Lx2+Vc/H45B+k5hao0X5IAk0GnhB1HBz0cDXqYHHRw0Otg1OtgNMg/mwzyz0a9Dg4GCUa9vuS9JL+W1LPVsXutZJ6t3FTys17HsEVEVB8w3FSiQYebGwkh9+xcOVM6pZ8Brp0D8tKBvCuAtfjW69EZAM9AoGl7wMUHcG8BdBwG+HQBdDpk5hXhYuZ1ZOcXIzu/qPS1oPiGsmLk5Bcjq0ydnIJiVDIeWnN6naQEH71Ogk4CdJIEnSTB0UEHJ6MBzkY9nIx6mI16mI0G+WcH+b2T0SC/Ouhh0Esw6HUw6CQ46HVw0Esl4cw+vNmCm14nQS9J0JVsV96+ZFdORNRYMNxUolGFm1sRAsjPlENObknYyUuXT3GlnwbSTwFXfgOKcitevkkbIGgM4NddDj0ufoCzN6Cv+vgbIQSKLAL5xRbkF1lQUGRFQbEF+UVW5BfJr4UWCwqLrSi0CPm12Ioii7WkzIqCsu/L/FxguaFuyc8FJcuVnyeqdAquPikNOlACz42hSELJqyRBUsKZ/CrZyiH3nMk/yT/Lr7aSkvkldZT5JTOkssvAfp1ymYSS/+zKyq6z0u1WUAbb8nb1StdZfrtSmfaVL0MF+1Zuf2+1XaVMsptnvx812G6Fx1myW+fNtlv2uCrvK9hGVdzstLFBVxK2hYDFKmARgE6Sy/U6HQQErLZvMTd83srug1UAFquAEMKunhCAAAAhIFDyvuRPl9Ggh06C8v+0QSd/idBVsmO32ufKZle2rFTpkpWvuPJtVrIvlW9Raa+uzBei6v7Zr2j7FW23bDVPsxH92nlVazu3Up2/3xwF2phJEuDkIU9N21ZcRwg57Fw5Lff85F0FLuwDzuyU79Hzv1dvXGnJ6S0vwOQCGJ0BgxPg4Ag4mAG9ETCY5ElvgmQwwag3wlicDzeTqzxfZwB0ekDSyz87OAEuHvKrziDXcfSQ11mYK59WM7kButt/4KgQokzwKQ1ThRYLLFbAKgSsJf+A5xdZkVdYjOuFFuQVWpBXZMH1wmLkFVpKywotuF4k1ym2yssVWwSKrHKwKiou3V5hmaBVaLHCUoUuLYtVwAIBWG5ZlYioztzV0kP1cFMdDDdUOUkC3JvLU5tBpeUF2cChtcC57+XTXNmpQG4aIKylA53rtJ06wMmzZGoivzo4lQYpg2NJsHKUA1J+JuDmXxKkDPLyOgMkBzNMAEyWQrkXytVP3ierpaSOXl6fg5Mc2sxNAH3tPPdLCKF8ky0bqqxWwGL72fZNuczP8mvJN2CIkm+5cjATQEloktdttcqvAravxij9ZlyybGmZKPn2bCsrXbco02bb8rZS23zbOu3LSgNc2W1WabsoW0/Yfbu32w/b8lXZbgVlZX8f1dpuueNX0XGu4nZvevxuOM4VLY/yrCUrKHcsKqh7K0KUfB4tQu4ZLOk5lD9r8pcECaU9hTceb9s+yJ01EvQ6KL0uVmErL9+DZuslKbRYIYSA0aCDQaeDRQgUFVtvui+37rS4eYXKlr3VaivrLalsWbW2KQSUL0w39pjK6xI3LFt5O25Vv4Ov6y1aV7t4WorUY7XIp7ZyUuUensIcuWelKA8oygeKr8uDnovz5UdOFOcDxQXy5OAIFOTI5VaLfG8fq0UeE1SUJ18SX1wAWIvk1/xMuY7OULVxQ7VF0gOerYAmbeVB2B4t5XJHd/lfD4NJ7rEC5FcnDwBSSdAq6aUyOMoDuYvy5MBUjdN6RESNBU9LkTZ0+pKxNz61vy2rFbAUyD0oRflAfoYcqK5fA66XvBYX2AcoJVQVyOHCFpCsxfZBCpDnZ12SxyDZenaEkOsU58tTUZ68/NXf5elM3O3vl9FVDkjWIrmtRlc5ENkCkslVPtWXkyq3R9KV9CjpSn+WdHLoKvu+0vmS3NNmO9VXdF2eivPlK+eMLiXHQCo9dsICWIpKTi86yMdF0st19EZ5nu3UYn6mPG7Lrbm8T5JeXkZXjRtDGpzk37WlqPR3KiwlXxcFlNOhxfnysSq6Ln8+jC5yeIQorat0p5RZtihPbo/eJIdwSSf/fP1aaW+do4e8fmux3JtXdpL0gFsz+epEYQUK8+R9tPUYFubIyzp6lPQEFsufWddm8jEpypPbbG4q75ekL1lPzg2/x5IwL+nkutZiebJ9KZCk0rrCKr9aS85Z6kp+54V58jImF7ncUiS/twVslITyouvy/jdtK5fZvnDYejKFRT5GDk7y9i0lV03a9jnvivyqd5CPs9VaeiytFvn3cyNbT5QQ8nZsXw6sRXJZcb7clrIDq4quy721KLOsjU4v1y/MlvfbwSzXKcyR2+DoUWZdZV4NppKujgL74y+E/HtzMMv/L0qS/O+P7TMBATg4l7QTJQOJLOU/L/LM0t8XJPnLTt4V+ZS+wdH+uNiNealgAJXt83w9Q26DpCvdVwdz6e/H9lm4cX9trzqD/OXK9u+hbT25afKp/4Jsuf1GZ0DnUPI7tH3mJPl3ff2a/Hs3NwV8Opf/HdcRhhu6M+l0gM5J/tnBEXDwk08h1SWrFchJkQddXzkDXP0NyPwDgCT/QbeFAVvvlaVQ/scBUpk/SMVyHVsXb2E2kHasbveDiEhtze4CJu7SbPMMN0Q1pdPJ39bdmgGt+9d8PcUlocfBEUg9JochvYP8zaggS/4mlJ9Z0gOQK9d1bip/u7N9E1S+HYqSHo0by2+Y7MotgMm95Ntsccl4Ikc5nF09W/LNEvI8g6P8Ldo2Vqm4oLQ3Rll3UZllLPIpOr2DPDDd6FzSA1bSW3DLaz0gr7M4X/6GbOsNMZjk7QMl346L5Sv+HJxKvqE7yd/aC3NLezSUb6iwf2+1lJ4S1Onk9du+eTt5yvOL8+Xfg21QvHRDT1hhtnwzTacm8r6ZXEt7GooLSr7plrTHduz0DnJvo4NZ/t3rHEp+zw6lPQFOnqW9GMJS2kvg4Cjvr209kl5ev6WodGyYpJO3r3OQ69l6Xhyc5P0uzCv9xm0wyb0GBseS5Up66PRGIPuSvD6doWQ7utLtFV2X69p68IDSU9DmpiU9NCVtkiB/ISjOLzkda7zh91/Si2ZrEyT5eFkKS/fHwal0cBFKjovOINezLWP7/dp6WiHkHlDbPtp6XfQOci+MQGmvi229xfklPYzG0u3Yelwc3eX9LsiW3xtM8jG2bT/3csn6jSXt05f2atp6kmz7W7Y30VIot6kwt3Rb5UaNlBv4Ys/JXX4tLvniJCzyzwZj6cUadj2YN7xai0rr23qqCrLk32VhrnIhCCwF8u/S9ju3Hb/C3NLPrGercv8r1yWGGyKtGYyAoan8c0AfbdtCRNQA3P61sypYtmwZAgMD4ejoiNDQUCQmJlZaf/369ejUqRMcHR3RvXt3bN26tY5aSkRERPWd5uFm3bp1mD59OubOnYv9+/ejZ8+eiIiIQFpaWoX1f/zxR4wePRpPPfUUDhw4gBEjRmDEiBE4evRoHbeciIiI6iPNLwUPDQ1F7969sXTpUgCA1WpFQEAApk6dipdeeqlc/VGjRiE3Nxdff/21UvanP/0JQUFBWLFixS23x0vBiYiI7jzV+futac9NYWEh9u3bh/DwcKVMp9MhPDwcCQkJFS6TkJBgVx8AIiIiblq/oKAAWVlZdhMRERE1XJqGm/T0dFgsFvj6+tqV+/r6IiUlpcJlUlJSqlU/JiYG7u7uyhQQEKBO44mIiKhe0nzMTW2bOXMmMjMzlen8+fNaN4mIiIhqkaaXgnt5eUGv1yM1NdWuPDU1FX5+Fd+Qzc/Pr1r1TSYTTCaTOg0mIiKiek/Tnhuj0Yjg4GDEx8crZVarFfHx8QgLC6twmbCwMLv6ABAXF3fT+kRERNS4aH4Tv+nTpyMqKgohISHo06cPYmNjkZubi+joaADA2LFj0bx5c8TExAAApk2bhoEDB+Kdd97B8OHDsXbtWvzyyy94//33tdwNIiIiqic0DzejRo3C5cuXMWfOHKSkpCAoKAjbt29XBg0nJydDpyvtYOrbty/WrFmDV155BS+//DLat2+PTZs2oVu3blrtAhEREdUjmt/npq7xPjdERER3njvmPjdEREREamO4ISIiogaF4YaIiIgaFM0HFNc12xAjPoaBiIjozmH7u12VocKNLtxkZ2cDAB/DQEREdAfKzs6Gu7t7pXUa3dVSVqsVFy9ehKurKyRJUnXdWVlZCAgIwPnz5xvtlVg8BjwGAI8BwGMA8BgAPAaAesdACIHs7Gw0a9bM7hYxFWl0PTc6nQ4tWrSo1W24ubk12g+xDY8BjwHAYwDwGAA8BgCPAaDOMbhVj40NBxQTERFRg8JwQ0RERA0Kw42KTCYT5s6d26ifQs5jwGMA8BgAPAYAjwHAYwBocwwa3YBiIiIiatjYc0NEREQNCsMNERERNSgMN0RERNSgMNwQERFRg8Jwo5Jly5YhMDAQjo6OCA0NRWJiotZNUs13332HyMhINGvWDJIkYdOmTXbzhRCYM2cO/P394eTkhPDwcJw+fdquztWrVzFmzBi4ubnBw8MDTz31FHJycupwL25PTEwMevfuDVdXV/j4+GDEiBE4efKkXZ38/HxMnjwZTZs2hYuLCx566CGkpqba1UlOTsbw4cNhNpvh4+ODv//97yguLq7LXamx5cuXo0ePHsqNuMLCwrBt2zZlfkPf/xu98cYbkCQJzz33nFLWGI7BvHnzIEmS3dSpUydlfmM4BhcuXMBf//pXNG3aFE5OTujevTt++eUXZX5j+DcxMDCw3OdAkiRMnjwZQD34HAi6bWvXrhVGo1GsXLlSHDt2TEyYMEF4eHiI1NRUrZumiq1bt4pZs2aJDRs2CABi48aNdvPfeOMN4e7uLjZt2iQOHTok/vKXv4jWrVuL69evK3WGDBkievbsKX766Sfx/fffi3bt2onRo0fX8Z7UXEREhFi1apU4evSoOHjwoBg2bJho2bKlyMnJUeo8/fTTIiAgQMTHx4tffvlF/OlPfxJ9+/ZV5hcXF4tu3bqJ8PBwceDAAbF161bh5eUlZs6cqcUuVdvmzZvFli1bxKlTp8TJkyfFyy+/LBwcHMTRo0eFEA1//8tKTEwUgYGBokePHmLatGlKeWM4BnPnzhVdu3YVly5dUqbLly8r8xv6Mbh69apo1aqVGDdunPj555/F77//Lnbs2CHOnDmj1GkM/yampaXZfQbi4uIEALFr1y4hhPafA4YbFfTp00dMnjxZeW+xWESzZs1ETEyMhq2qHTeGG6vVKvz8/MTbb7+tlGVkZAiTySS++OILIYQQx48fFwDE3r17lTrbtm0TkiSJCxcu1Fnb1ZSWliYAiG+//VYIIe+zg4ODWL9+vVLnxIkTAoBISEgQQsghUafTiZSUFKXO8uXLhZubmygoKKjbHVCJp6en+PDDDxvV/mdnZ4v27duLuLg4MXDgQCXcNJZjMHfuXNGzZ88K5zWGY/Diiy+Ku++++6bzG+u/idOmTRNt27YVVqu1XnwOeFrqNhUWFmLfvn0IDw9XynQ6HcLDw5GQkKBhy+rG2bNnkZKSYrf/7u7uCA0NVfY/ISEBHh4eCAkJUeqEh4dDp9Ph559/rvM2qyEzMxMA0KRJEwDAvn37UFRUZHccOnXqhJYtW9odh+7du8PX11epExERgaysLBw7dqwOW3/7LBYL1q5di9zcXISFhTWq/Z88eTKGDx9ut69A4/oMnD59Gs2aNUObNm0wZswYJCcnA2gcx2Dz5s0ICQnBI488Ah8fH/Tq1QsffPCBMr8x/ptYWFiIzz77DE8++SQkSaoXnwOGm9uUnp4Oi8Vi9wsCAF9fX6SkpGjUqrpj28fK9j8lJQU+Pj528w0GA5o0aXJHHiOr1YrnnnsO/fr1Q7du3QDI+2g0GuHh4WFX98bjUNFxss27Exw5cgQuLi4wmUx4+umnsXHjRnTp0qXR7P/atWuxf/9+xMTElJvXWI5BaGgoVq9eje3bt2P58uU4e/Ys+vfvj+zs7EZxDH7//XcsX74c7du3x44dOzBp0iQ8++yz+PjjjwE0zn8TN23ahIyMDIwbNw5A/fh/odE9FZzodk2ePBlHjx7FDz/8oHVT6lzHjh1x8OBBZGZm4ssvv0RUVBS+/fZbrZtVJ86fP49p06YhLi4Ojo6OWjdHM0OHDlV+7tGjB0JDQ9GqVSv85z//gZOTk4YtqxtWqxUhISFYuHAhAKBXr144evQoVqxYgaioKI1bp42PPvoIQ4cORbNmzbRuioI9N7fJy8sLer2+3Cjw1NRU+Pn5adSqumPbx8r238/PD2lpaXbzi4uLcfXq1TvuGE2ZMgVff/01du3ahRYtWijlfn5+KCwsREZGhl39G49DRcfJNu9OYDQa0a5dOwQHByMmJgY9e/bEv/71r0ax//v27UNaWhruuusuGAwGGAwGfPvtt3j33XdhMBjg6+vb4I9BRTw8PNChQwecOXOmUXwO/P390aVLF7uyzp07K6fmGtu/iUlJSdi5cyfGjx+vlNWHzwHDzW0yGo0IDg5GfHy8Uma1WhEfH4+wsDANW1Y3WrduDT8/P7v9z8rKws8//6zsf1hYGDIyMrBv3z6lzv/+9z9YrVaEhobWeZtrQgiBKVOmYOPGjfjf//6H1q1b280PDg6Gg4OD3XE4efIkkpOT7Y7DkSNH7P5Ri4uLg5ubW7l/LO8UVqsVBQUFjWL/Bw8ejCNHjuDgwYPKFBISgjFjxig/N/RjUJGcnBz89ttv8Pf3bxSfg379+pW7DcSpU6fQqlUrAI3n30SbVatWwcfHB8OHD1fK6sXn4LaHJJNYu3atMJlMYvXq1eL48eNi4sSJwsPDw24U+J0sOztbHDhwQBw4cEAAEIsXLxYHDhwQSUlJQgj5skcPDw/x1VdficOHD4sHHnigwssee/XqJX7++Wfxww8/iPbt299Rlz1OmjRJuLu7i927d9td/piXl6fUefrpp0XLli3F//73P/HLL7+IsLAwERYWpsy3Xfp4//33i4MHD4rt27cLb2/vO+YS2Jdeekl8++234uzZs+Lw4cPipZdeEpIkiW+++UYI0fD3vyJlr5YSonEcgxdeeEHs3r1bnD17VuzZs0eEh4cLLy8vkZaWJoRo+McgMTFRGAwG8frrr4vTp0+Lzz//XJjNZvHZZ58pdRrDv4lCyFcGt2zZUrz44ovl5mn9OWC4UcmSJUtEy5YthdFoFH369BE//fST1k1Sza5duwSAclNUVJQQQr70cfbs2cLX11eYTCYxePBgcfLkSbt1XLlyRYwePVq4uLgINzc3ER0dLbKzszXYm5qpaP8BiFWrVil1rl+/Lp555hnh6ekpzGazGDlypLh06ZLdes6dOyeGDh0qnJychJeXl3jhhRdEUVFRHe9NzTz55JOiVatWwmg0Cm9vbzF48GAl2AjR8Pe/IjeGm8ZwDEaNGiX8/f2F0WgUzZs3F6NGjbK7x0tjOAb//e9/Rbdu3YTJZBKdOnUS77//vt38xvBvohBC7NixQwAot29CaP85kIQQ4vb7f4iIiIjqB465ISIiogaF4YaIiIgaFIYbIiIialAYboiIiKhBYbghIiKiBoXhhoiIiBoUhhsiIiJqUBhuiKhRkiQJmzZt0roZRFQLGG6IqM6NGzcOkiSVm4YMGaJ104ioATBo3QAiapyGDBmCVatW2ZWZTCaNWkNEDQl7bohIEyaTCX5+fnaTp6cnAPmU0fLlyzF06FA4OTmhTZs2+PLLL+2WP3LkCO699144OTmhadOmmDhxInJycuzqrFy5El27doXJZIK/vz+mTJliNz89PR0jR46E2WxG+/btsXnzZmXetWvXMGbMGHh7e8PJyQnt27cvF8aIqH5iuCGiemn27Nl46KGHcOjQIYwZMwaPPfYYTpw4AQDIzc1FREQEPD09sXfvXqxfvx47d+60Cy/Lly/H5MmTMXHiRBw5cgSbN29Gu3bt7LYxf/58PProozh8+DCGDRuGMWPG4OrVq8r2jx8/jm3btuHEiRNYvnw5vLy86u4AEFHNqfL4TSKiaoiKihJ6vV44OzvbTa+//roQQn4K+9NPP223TGhoqJg0aZIQQoj3339feHp6ipycHGX+li1bhE6nEykpKUIIIZo1ayZmzZp10zYAEK+88oryPicnRwAQ27ZtE0IIERkZKaKjo9XZYSKqUxxzQ0SauOeee7B8+XK7siZNmig/h4WF2c0LCwvDwYMHAQAnTpxAz5494ezsrMzv168frFYrTp48CUmScPHiRQwePLjSNvTo0UP52dnZGW5ubkhLSwMATJo0CQ899BD279+P+++/HyNGjEDfvn1rtK9EVLcYbohIE87OzuVOE6nFycmpSvUcHBzs3kuSBKvVCgAYOnQokpKSsHXrVsTFxWHw4MGYPHkyFi1apHp7iUhdHHNDRPXSTz/9VO59586dAQCdO3fGoUOHkJubq8zfs2cPdDodOnbsCFdXVwQGBiI+Pv622uDt7Y2oqCh89tlniI2Nxfvvv39b6yOiusGeGyLSREFBAVJSUuzKDAaDMmh3/fr1CAkJwd13343PP/8ciYmJ+OijjwAAY8aMwdy5cxEVFYV58+bh8uXLmDp1Kp544gn4+voCAObNm4enn34aPj4+GDp0KLKzs7Fnzx5MnTq1Su2bM2cOgoOD0bVrVxQUFODrr79WwhUR1W8MN0Skie3bt8Pf39+urGPHjvj1118ByFcyrV27Fs888wz8/f3xxRdfoEuXLgAAs9mMHTt2YNq0aejduzfMZjMeeughLF68WFlXVFQU8vPz8c9//hMzZsyAl5cXHn744Sq3z2g0YubMmTh37hycnJzQv39/rF27VoU9J6LaJgkhhNaNICIqS5IkbNy4ESNGjNC6KUR0B+KYGyIiImpQGG6IiIioQeGYGyKqd3i2nIhuB3tuiIiIqEFhuCEiIqIGheGGiIiIGhSGGyIiImpQGG6IiIioQWG4ISIiogaF4YaIiIgaFIYbIiIialAYboiIiKhB+X9nN8ed2hbPFAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.save('autoencoder_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgrGQFT3gGe3",
        "outputId": "40eb6e8c-151e-4003-a346-37123309dc0b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = models.load_model('/content/autoencoder_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d1lZP-rgEQZ",
        "outputId": "db91d8b0-388d-4afa-fe30-61539e3998e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}